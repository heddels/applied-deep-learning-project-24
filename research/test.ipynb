{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-09T16:50:05.185845Z",
     "start_time": "2024-12-09T16:50:05.180500Z"
    }
   },
   "source": "import os",
   "outputs": [],
   "execution_count": 266
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:50:05.369074Z",
     "start_time": "2024-12-09T16:50:05.366966Z"
    }
   },
   "cell_type": "code",
   "source": "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"",
   "id": "fc51803bfb9245a1",
   "outputs": [],
   "execution_count": 267
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:50:05.661965Z",
     "start_time": "2024-12-09T16:50:05.657841Z"
    }
   },
   "cell_type": "code",
   "source": "%pwd",
   "id": "e0e2eebc1f516b7f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/heddafiedler/Documents/MASTER_DATA_SCIENCE/Semester_3/DL/DL_Project'"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 268
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:50:06.160646Z",
     "start_time": "2024-12-09T16:50:06.158840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# changing working directory to the root of the project:/Users/heddafiedler/Documents/MASTER_DATA_SCIENCE/Semester_3/DL/DL_Project\n",
    "os.chdir(\"/Users/heddafiedler/Documents/MASTER_DATA_SCIENCE/Semester_3/DL/DL_Project\")"
   ],
   "id": "4c54405f4edde846",
   "outputs": [],
   "execution_count": 269
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Purpose of the Notebook\n",
    "\n",
    "In this notebook I create the pipeline for using the model built in the MAGPIE Repository in order to understand its components and test how the elements work together.\n",
    "Besides, I already look into the parts I want to change, like more detailed logging / debugging steps to better understand the process. Apart from that I will use the code provided by the Repository.\n",
    "\n",
    "In order to understand the core elements of the model architecture and pipeline, I will only display the main parts here and import utils and other functions."
   ],
   "id": "34ee8ec75e326ea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Ingestion and Preprocessing\n",
    "Since the repository already provides the datasets in a preprocessed way, I will use these files for the model training according to the data sets I chose (see README file).\n",
    "Nevertheless, I will need to include data preprocessing in order to do inference on new data. Therefore, the following part tests the preporcessing of random text input and the tokenization of the text."
   ],
   "id": "4bfa411557c18a2f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:50:08.157145Z",
     "start_time": "2024-12-09T16:50:07.868503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "from media_bias_detection.utils.logger import general_logger\n",
    "\n",
    "\n",
    "class Tokenizer:\n",
    "    \"\"\"Singleton class to maintain a single tokenizer instance.\"\"\"\n",
    "\n",
    "    _instance = None\n",
    "    _tokenizer = None\n",
    "\n",
    "    def __new__(cls):\n",
    "        if cls._instance is None:\n",
    "            cls._instance = super(Tokenizer, cls).__new__(cls)\n",
    "            cls._tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "        return cls._instance\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return vocabulary size\"\"\"\n",
    "        return len(self._tokenizer)  # Add this method\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        \"\"\"Make the tokenizer callable directly.\"\"\"\n",
    "        return self._tokenizer(*args, **kwargs)\n",
    "\n",
    "    @property\n",
    "    def tokenizer(self):\n",
    "        return self._tokenizer\n",
    "\n",
    "\n",
    "# Global tokenizer instance\n",
    "tokenizer = Tokenizer()"
   ],
   "id": "3aeab84bb699e614",
   "outputs": [],
   "execution_count": 270
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:50:08.753516Z",
     "start_time": "2024-12-09T16:50:08.745430Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = \"This is a test\"\n",
    "tokenized = tokenizer(text, truncation=True, return_tensors=\"pt\")\n",
    "print(tokenized)"
   ],
   "id": "87f5ba0464052811",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 101, 2023, 2003, 1037, 3231,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "execution_count": 271
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Initialization with Task and Subtask Classes\n",
    "Since the MTL approach is about combining different tasks, the data needs to contain the information bout which model head it needs in the model pipeline.\n",
    "I will use the Task and Subtask classes from the MAGPIE Repository to create the tasks I want to use. The tasks are defined in the following part.\n",
    "\n",
    "The Sub Tasks I am going to use according to the datasets I chose are:\n",
    "- Token-Level Classification (POS) --> noch besser verstehen was das genau ist\n",
    "- Binary Classification\n",
    "- Multi-Class Classification\n",
    "- (Regression) - not used in current implementation\n",
    "- (Masked Language Modelling) - not used in current implementation\n",
    "\n",
    "The Subtask class defines how to load and structure the respective data set, as well as other functions like weight scaling and class weights for imbalanced datasets\n",
    "\n",
    "The Task class is a wrapper for the subtasks and contains the task id and the subtasks list. Since I am using only one dataset for each subtask, the subtask list contains only one subtask. Nevertheless, I am leaving the wrapper in the code in order to use the other steps in the same way as in the repository.\n",
    "\n",
    "The SubTaskDataset class creates then the actual data loaders and also contains the BatchList class for Training and for Evaluation.\n",
    "\n"
   ],
   "id": "a01c107148bf6d4d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:50:14.379319Z",
     "start_time": "2024-12-09T16:50:14.377097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from typing import List, Tuple, Optional, Dict\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "from media_bias_detection.utils.common import get_class_weights\n",
    "from media_bias_detection.utils.enums import Split\n",
    "from media_bias_detection.utils.logger import general_logger\n",
    "from media_bias_detection.config.config import DEV_RATIO, MAX_LENGTH, REGRESSION_SCALAR, TRAIN_RATIO\n"
   ],
   "id": "5bf648f5c7dc733c",
   "outputs": [],
   "execution_count": 272
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:50:15.056908Z",
     "start_time": "2024-12-09T16:50:15.055291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DataProcessingError(Exception):\n",
    "    \"\"\"Custom exception for data processing errors.\"\"\"\n",
    "    pass"
   ],
   "id": "caeda0a1c4bb2580",
   "outputs": [],
   "execution_count": 273
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:50:15.575811Z",
     "start_time": "2024-12-09T16:50:15.572600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"This part contains the Task class.\"\"\"\n",
    "\n",
    "class Task:\n",
    "    \"\"\"Wrap subtasks.\"\"\"\n",
    "\n",
    "    def __init__(self, task_id, subtasks_list):\n",
    "        \"\"\"Initialize a Task.\"\"\"\n",
    "        self.task_id = task_id\n",
    "        self.subtasks_list = subtasks_list\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"Represent a task.\"\"\"\n",
    "        return (\n",
    "            f\"Task {self.task_id} with {len(self.subtasks_list)} subtask{'s' if len(self.subtasks_list) > 1 else ''}\"\n",
    "        )\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return str(self.task_id)"
   ],
   "id": "d5f6d49dd2ec6c13",
   "outputs": [],
   "execution_count": 274
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:50:16.074016Z",
     "start_time": "2024-12-09T16:50:16.068668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "def get_pos_idxs(pos: str, text: str):\n",
    "    \"\"\"\n",
    "    Get the correct idxs of the pos for a given text.\n",
    "\n",
    "    @param pos: A pattern as text.\n",
    "    @param text: The text to search trough.\n",
    "    @return: The ids of the tokens in the text that match the pattern.\n",
    "    \"\"\"\n",
    "    if pos == text:\n",
    "        mask = np.array(np.ones((len(text))), dtype=\"int\")\n",
    "    else:\n",
    "        pos = pos.replace(\"[\", \"\\[\")\n",
    "        pos = pos.replace(\"$\", \"\\$\")\n",
    "        pos = pos.replace(\"?\", \"\\?\")\n",
    "        pos = pos.replace(\")\", \"\\)\")\n",
    "        pos = pos.replace(\"(\", \"\\(\")\n",
    "        pos = pos.replace(\"*\", \"\\*\")\n",
    "        pos = pos.replace(\"+\", \"\\+\")\n",
    "        start, end = re.search(pos, text).span()\n",
    "\n",
    "        mask = np.zeros((len(text)), dtype=int)\n",
    "        mask[start:end] = 1\n",
    "    c, idx_list = 0, []\n",
    "    for t in text.split():\n",
    "        idx_list.append(c)\n",
    "        c += len(t) + 1\n",
    "    mask_idxs = [mask[i] for i in idx_list]\n",
    "    return mask_idxs\n",
    "\n",
    "\n",
    "def align_labels_with_tokens(labels: List[int], word_ids: List[int]):\n",
    "    \"\"\"Align labels with tokens.\n",
    "\n",
    "    C/p from https://huggingface.co/course/chapter7/2\n",
    "    \"\"\"\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = (\n",
    "                -100 if word_id is None else labels[word_id]\n",
    "            )  # -100 is an index that will be ignored by cross entropy\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels\n",
    "\n",
    "\n",
    "def get_tokens_and_labels(pos_list_list, text_list, labels):\n",
    "    \"\"\"Get tokens and labels for scattered POS.\n",
    "\n",
    "    In this objective, we have a list of consecutive spans.\n",
    "    For each of these consecutive spans, find the correct index of the corresponding tokens in the text_list.\n",
    "    Returns the bitwise or ('union') of this ids.\n",
    "    \"\"\"\n",
    "    mask_idxs_list = []\n",
    "    for i, pos_list in enumerate(pos_list_list):\n",
    "        label = labels[i]\n",
    "        text = text_list[i]\n",
    "        observation_mask_idxs = []\n",
    "        for pos in pos_list:\n",
    "            if len(pos) == 0:\n",
    "                # If there is no POS, we just return zeros\n",
    "                observation_mask_idxs.append(get_pos_idxs(\"\", text))\n",
    "            else:\n",
    "                for pos in pos_list:\n",
    "                    if label == 0:  # In that case, the label is the neutral class\n",
    "                        observation_mask_idxs.append(get_pos_idxs(pos, text))\n",
    "                    else:\n",
    "                        pos_idxs = get_pos_idxs(pos, text)\n",
    "                        pos_idxs = [label if idx == 1 else 0 for idx in pos_idxs]\n",
    "                        observation_mask_idxs.append(pos_idxs)\n",
    "\n",
    "        # reduce observation_mask_idxs\n",
    "        observation_mask_idxs = np.bitwise_or.reduce(observation_mask_idxs, axis=0)\n",
    "        mask_idxs_list.append(observation_mask_idxs)\n",
    "\n",
    "    return [t.split() for t in text_list], mask_idxs_list"
   ],
   "id": "2d702ae4dd058b68",
   "outputs": [],
   "execution_count": 275
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:50:16.861735Z",
     "start_time": "2024-12-09T16:50:16.829187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"This part contains the Subtask.\"\"\"\n",
    "class SubTask:\n",
    "    \"\"\"Base class for all subtasks.\n",
    "\n",
    "    Attributes:\n",
    "        id: Unique identifier for the subtask\n",
    "        task_id: ID of parent task\n",
    "        filename: Path to data file\n",
    "        src_col: Column name for input text\n",
    "        tgt_cols_list: List of target column names\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            id: int,\n",
    "            task_id: int,\n",
    "            filename: str,\n",
    "            src_col: str = \"text\",\n",
    "            tgt_cols_list: List[str] = [\"label\"],\n",
    "            cache_dir: Optional[str] = None\n",
    "    ):\n",
    "        if type(self) == SubTask:\n",
    "            raise RuntimeError(\"Abstract class <SubTask> must not be instantiated.\")\n",
    "\n",
    "        self.id = id\n",
    "        self.task_id = task_id\n",
    "        self.src_col = src_col\n",
    "        self.tgt_cols_list = tgt_cols_list\n",
    "        self.filename = Path(os.path.join(\"datasets\", filename))\n",
    "        self.cache_dir = Path(cache_dir) if cache_dir else None\n",
    "\n",
    "        # Data attributes\n",
    "        self.attention_masks: Optional[Dict[Split, torch.Tensor]] = None\n",
    "        self.X: Optional[Dict[Split, torch.Tensor]] = None\n",
    "        self.Y: Optional[Dict[Split, torch.Tensor]] = None\n",
    "        self.class_weights: Optional[torch.Tensor] = None\n",
    "        self.processed = False\n",
    "\n",
    "        general_logger.info(\n",
    "            f\"Initialized SubTask {id} for task {task_id} \"\n",
    "            f\"using file {self.filename}\"\n",
    "        )\n",
    "\n",
    "    def process(self, force_download: bool = False) -> None:\n",
    "        \"\"\"Process and split the data.\n",
    "\n",
    "        Args:\n",
    "            force_download: Whether to force data reprocessing\n",
    "\n",
    "        Raises:\n",
    "            DataProcessingError: If data processing fails\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Check cache first\n",
    "            if self.cache_dir and not force_download:\n",
    "                if self._load_from_cache():\n",
    "                    return\n",
    "\n",
    "            general_logger.info(f\"Processing SubTask {self.id}\")\n",
    "            X, Y, attention_masks = self.load_data()\n",
    "\n",
    "            # Validate data\n",
    "            if not (len(X) == len(Y) == len(attention_masks)):\n",
    "                raise DataProcessingError(\"Mismatched lengths in processed data\")\n",
    "\n",
    "            # Split data\n",
    "            train_split = int(len(X) * TRAIN_RATIO)\n",
    "            dev_split = train_split + int(len(X) * DEV_RATIO)\n",
    "\n",
    "            self.X = {Split.TRAIN: X[:train_split], Split.DEV: X[train_split:dev_split],\n",
    "                      Split.TEST: X[dev_split:]}\n",
    "\n",
    "            self.attention_masks = {\n",
    "                Split.TRAIN: attention_masks[:train_split],\n",
    "                Split.DEV: attention_masks[train_split:dev_split],\n",
    "                Split.TEST: attention_masks[dev_split:],\n",
    "            }\n",
    "            self.Y = {Split.TRAIN: Y[:train_split], Split.DEV: Y[train_split:dev_split],\n",
    "                      Split.TEST: Y[dev_split:]}\n",
    "\n",
    "            self.create_class_weights()\n",
    "            self._save_to_cache()\n",
    "\n",
    "            self.processed = True\n",
    "            general_logger.info(\n",
    "                f\"SubTask {self.id} processed successfully. \"\n",
    "                f\"Splits: Train={len(self.X[Split.TRAIN])}, \"\n",
    "                f\"Dev={len(self.X[Split.DEV])}, \"\n",
    "                f\"Test={len(self.X[Split.TEST])}\"\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            raise DataProcessingError(f\"Failed to process subtask {self.id}: {str(e)}\")\n",
    "\n",
    "    def _load_from_cache(self) -> bool:\n",
    "        \"\"\"Try to load processed data from cache.\"\"\"\n",
    "        if not self.cache_dir:\n",
    "            return False\n",
    "\n",
    "        cache_file = self.cache_dir / f\"subtask_{self.id}.pt\"\n",
    "        if cache_file.exists():\n",
    "            try:\n",
    "                cached_data = torch.load(cache_file)\n",
    "                self.X = cached_data['X']\n",
    "                self.Y = cached_data['Y']\n",
    "                self.attention_masks = cached_data['attention_masks']\n",
    "                self.class_weights = cached_data.get('class_weights')\n",
    "                self.processed = True\n",
    "                general_logger.info(f\"Loaded cached data for SubTask {self.id}\")\n",
    "                return True\n",
    "            except Exception as e:\n",
    "                general_logger.warning(f\"Failed to load cache for SubTask {self.id}: {e}\")\n",
    "                return False\n",
    "        return False\n",
    "\n",
    "    def _save_to_cache(self) -> None:\n",
    "        \"\"\"Save processed data to cache.\"\"\"\n",
    "        if not self.cache_dir:\n",
    "            return\n",
    "\n",
    "        self.cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "        cache_file = self.cache_dir / f\"subtask_{self.id}.pt\"\n",
    "\n",
    "        try:\n",
    "            torch.save({\n",
    "                'X': self.X,\n",
    "                'Y': self.Y,\n",
    "                'attention_masks': self.attention_masks,\n",
    "                'class_weights': self.class_weights\n",
    "            }, cache_file)\n",
    "            general_logger.info(f\"Saved cache for SubTask {self.id}\")\n",
    "        except Exception as e:\n",
    "            general_logger.warning(f\"Failed to save cache for SubTask {self.id}: {e}\")\n",
    "\n",
    "    # Abstract methods\n",
    "    def load_data(self) -> Tuple:\n",
    "        \"\"\"Load the data of a SubTask.\n",
    "\n",
    "        Must be implemented for inherited.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def create_class_weights(self):\n",
    "        \"\"\"Compute the weights for imbalanced classes.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def get_scaling_weight(self):\n",
    "        \"\"\"Get the scaling weight of a Subtask.\n",
    "\n",
    "        Needs to be overwritten.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_X(self, split: Split):\n",
    "        \"\"\"Get all X of a given split.\"\"\"\n",
    "        return self.X[split]\n",
    "\n",
    "    def get_att_mask(self, split: Split):\n",
    "        \"\"\"Get attention_masks for inputs of a given split.\"\"\"\n",
    "        return self.attention_masks[split]\n",
    "\n",
    "    def get_Y(self, split: Split):\n",
    "        \"\"\"Get all Y of a given split.\"\"\"\n",
    "        return self.Y[split]\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return str(self.id)\n",
    "\n",
    "# a[43485:43500]\n",
    "class ClassificationSubTask(SubTask):\n",
    "    \"\"\"A ClassificationSubTask.\"\"\"\n",
    "\n",
    "    def __init__(self, num_classes=2, *args, **kwargs):\n",
    "        \"\"\"Initialize a ClassificationSubTask.\"\"\"\n",
    "        super(ClassificationSubTask, self).__init__(*args, **kwargs)\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def load_data(self) -> Tuple[torch.LongTensor, torch.LongTensor, torch.LongTensor]:\n",
    "        \"\"\"Load the data of a ClassificationSubTask.\"\"\"\n",
    "        df = pd.read_csv(self.filename)\n",
    "\n",
    "        X, Y = df[self.src_col], df[self.tgt_cols_list]\n",
    "        tokenized_inputs = tokenizer(X.to_list(), padding=\"max_length\", truncation=True,\n",
    "                                     max_length=MAX_LENGTH)\n",
    "        X = tokenized_inputs.get(\"input_ids\")\n",
    "        attention_masks = tokenized_inputs.get(\"attention_mask\")\n",
    "        assert Y.nunique().squeeze() == self.num_classes\n",
    "        assert Y[self.tgt_cols_list[0]].min(axis=0) == 0\n",
    "        if self.num_classes == 2:  # if it's binary classification\n",
    "            Y = Y.to_numpy()\n",
    "        else:\n",
    "            Y = Y[self.tgt_cols_list].to_numpy()\n",
    "        return torch.LongTensor(X), torch.LongTensor(Y), torch.LongTensor(attention_masks)\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"Represent a Classification Subtask.\"\"\"\n",
    "        return f\"{'Multi-class' if self.num_classes != 2 else 'Binary'} Classification\"\n",
    "\n",
    "    def create_class_weights(self):\n",
    "        \"\"\"Compute the weights.\"\"\"\n",
    "        self.class_weights = get_class_weights(self.Y[Split.TRAIN], method=\"isns\")\n",
    "\n",
    "    def get_scaling_weight(self):\n",
    "        \"\"\"Get the weight of a Classification Subtask.\n",
    "\n",
    "        As with the other tasks, we normalize by the natural logarithm of the domain size.\n",
    "        \"\"\"\n",
    "        return 1 / np.log(self.num_classes)\n",
    "\n",
    "\n",
    "# in current implementation, the regression subtask is not used\n",
    "class RegressionSubTask(SubTask):\n",
    "    \"\"\"A RegressionSubTask.\"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        \"\"\"Initialize a RegressionSubTask.\"\"\"\n",
    "        super(RegressionSubTask, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def load_data(self) -> Tuple[torch.LongTensor, torch.FloatTensor, torch.LongTensor]:\n",
    "        \"\"\"Load the data of a RegressionSubTask.\"\"\"\n",
    "        df = pd.read_csv(self.filename)\n",
    "        X, Y = df[self.src_col], df[self.tgt_cols_list]\n",
    "        tokenized_inputs = tokenizer(X.to_list(), padding=\"max_length\", truncation=True,\n",
    "                                     max_length=MAX_LENGTH)\n",
    "        X = tokenized_inputs.get(\"input_ids\")\n",
    "        attention_masks = tokenized_inputs.get(\"attention_mask\")\n",
    "        Y = (((Y - Y.min()) / (Y.max() - Y.min())).to_numpy()).astype(\"float32\")  # scale from 0 to 1\n",
    "        return torch.LongTensor(X), torch.FloatTensor(Y), torch.LongTensor(attention_masks)\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"Represent a Regression Subtask.\"\"\"\n",
    "        return \"Regression\"\n",
    "\n",
    "    def get_scaling_weight(self):\n",
    "        \"\"\"Get the scaling weight of a Regression Subtask.\n",
    "\n",
    "        As of now, this scaling weight is a simple scalar and is a mere heuristic-based approximation (ie. we eyeballed it).\n",
    "        \"\"\"\n",
    "        return REGRESSION_SCALAR\n",
    "\n",
    "\n",
    "class MultiLabelClassificationSubTask(SubTask):\n",
    "    \"\"\"A MultiLabelClassificationSubTask.\"\"\"\n",
    "\n",
    "    def __init__(self, num_classes=2, num_labels=2, *args, **kwargs):\n",
    "        \"\"\"Initialize a MultiLabelClassificationSubTask.\"\"\"\n",
    "        super(MultiLabelClassificationSubTask, self).__init__(*args, **kwargs)\n",
    "        self.num_classes = None\n",
    "        self.num_classes = num_classes\n",
    "        self.num_labels = num_labels\n",
    "        print(f\"MultiClass Subtask {self.id}:\\nNum classes: {num_classes}, Num labels: {num_labels}\")\n",
    "\n",
    "\n",
    "    def load_data(self) -> Tuple[torch.LongTensor, torch.LongTensor, torch.LongTensor]:\n",
    "        \"\"\"Load the data of a MultiLabelClassificationSubTask.\"\"\"\n",
    "        print(f\"Loading data for MultiLabelClassificationSubTask {self.id}\")\n",
    "        df = pd.read_csv(self.filename)\n",
    "    \n",
    "        #X = df[self.src_col].tolist()\n",
    "        #Y = df[self.tgt_cols_list].values\n",
    "        X, Y = df[self.src_col], df[self.tgt_cols_list]\n",
    "        \n",
    "        print(f\"X type: {type(X)}\")\n",
    "        print(f\"Y type: {type(Y)}\")\n",
    "        print(f\"X shape: {len(X)}\")\n",
    "        print(f\"Y shape: {Y.shape}\")\n",
    "    \n",
    "        tokenized_inputs = tokenizer(X.tolist(), padding=\"max_length\", truncation=True,\n",
    "                                     max_length=MAX_LENGTH)\n",
    "        X = torch.LongTensor(tokenized_inputs.get(\"input_ids\"))\n",
    "        attention_masks = torch.LongTensor(tokenized_inputs.get(\"attention_mask\"))\n",
    "        assert Y.max(axis=0).to_numpy().max() == 1\n",
    "        Y = Y.to_numpy()\n",
    "        Y = torch.LongTensor(Y)\n",
    "    \n",
    "        print(f\"X shape: {X.shape}\")\n",
    "        print(f\"Y shape: {Y.shape}\")\n",
    "        print(f\"Attention masks shape: {attention_masks.shape}\")\n",
    "    \n",
    "        return X, Y, attention_masks\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"Represent a Multi-label Classification Subtask.\"\"\"\n",
    "        return \"Multi-label Classification\"\n",
    "\n",
    "    def get_scaling_weight(self):\n",
    "        \"\"\"Get the weight of a Multi-label Classification Subtask.\n",
    "\n",
    "        As with the other tasks, we normalize by the natural logarithm of the domain size.\n",
    "        \"\"\"\n",
    "        return 1 / np.log(self.num_classes * self.num_labels)\n",
    "\n",
    "\n",
    "class POSSubTask(SubTask):\n",
    "    \"\"\"A POSSubTask.\n",
    "\n",
    "    Each POSSubTask can be either binary classification or multiclass classification.\n",
    "    If it is binary classification, zero (0) must be the neutral class.\n",
    "    This neutral class is also applied to all other, 'normal' tokens.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tgt_cols_list, label_col=None, *args, **kwargs):\n",
    "        \"\"\"Initialize a POSSubTask.\n",
    "\n",
    "        Normally, we have 3 classes: (0=no-tag, 1=tag-start, 2=tag-continue)\n",
    "        However, we have POS-tasks where we have more than just 'binary token level classification'.\n",
    "        In these scenarios, each class has two tags: 'tag-start' and 'tag-continue'.\n",
    "        The 'no-class' tag has no 'tag-continue'.\n",
    "        \"\"\"\n",
    "        self.num_classes = 3  # The default num_classes is 2 or 3 (0=no-tag, 1=tag-start, 2=tag-continue)\n",
    "        self.label_col = label_col\n",
    "        assert len(tgt_cols_list) == 1\n",
    "        super(POSSubTask, self).__init__(tgt_cols_list=tgt_cols_list, *args, **kwargs)\n",
    "\n",
    "    def load_data(self) -> Tuple[torch.LongTensor, torch.LongTensor, torch.LongTensor]:\n",
    "        \"\"\"Load the data of a POSSubTask.\"\"\"\n",
    "        df = pd.read_csv(self.filename)\n",
    "\n",
    "        df[self.tgt_cols_list] = df[self.tgt_cols_list].fillna(\"\")\n",
    "        mask = df.apply(\n",
    "            lambda row: all([p in row[self.src_col] for p in row[self.tgt_cols_list[0]].split(\";\")]), axis=1\n",
    "        )\n",
    "        df = df[mask].reset_index(drop=True)\n",
    "        assert sum(mask) == len(df[self.tgt_cols_list]), \"At least one POS is not contained in the source column.\"\n",
    "\n",
    "        pos_list_list = df[self.tgt_cols_list[0]].apply(lambda x: x.split(\";\")).to_list()\n",
    "        X = df[self.src_col].values\n",
    "        # If we do not provide a labels column, we assume that, whenever a pos is present, that is the non-neutral class\n",
    "        labels = (\n",
    "            df[self.label_col]\n",
    "            if self.label_col\n",
    "            else [1 if len(pos) > 0 else 0 for pos in df[self.tgt_cols_list[0]].to_list()]\n",
    "        )\n",
    "        tokens, labels = get_tokens_and_labels(pos_list_list=pos_list_list, text_list=X, labels=labels)\n",
    "        tokenized_inputs = tokenizer(\n",
    "            tokens, padding=\"max_length\", is_split_into_words=True, truncation=True,\n",
    "            max_length=MAX_LENGTH\n",
    "        )\n",
    "        new_labels = []\n",
    "        for i, labels in enumerate(labels):\n",
    "            word_ids = tokenized_inputs.word_ids(i)\n",
    "            new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "        Y = np.array(new_labels)\n",
    "        # This should in most cases not alter self.num_classes, as we only use binary tags (+ tag-continue = 3 classes).\n",
    "        # However, we leave this generic implementation for future tasks.\n",
    "        self.num_classes = len(np.unique(Y)) - 1\n",
    "        X = tokenized_inputs.get(\"input_ids\")\n",
    "        attention_masks = tokenized_inputs.get(\"attention_mask\")\n",
    "        return torch.LongTensor(X), torch.LongTensor(Y), torch.LongTensor(attention_masks)\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"Represent a Token-level classification Subtask.\"\"\"\n",
    "        return \"Token-level classification\"\n",
    "\n",
    "    def create_class_weights(self):\n",
    "        \"\"\"Compute the weights.\"\"\"\n",
    "        labels = self.Y[Split.TRAIN]\n",
    "        only_class_labels = labels[labels != -100]\n",
    "        self.class_weights = get_class_weights(only_class_labels, method=\"isns\")\n",
    "\n",
    "    def get_scaling_weight(self):\n",
    "        \"\"\"Get the weight of a POS Subtask.\n",
    "\n",
    "        As with the other tasks, we normalize by the natural logarithm of the domain size.\n",
    "        In case of POS subtask, the domain size equals the vocab size.\n",
    "        \"\"\"\n",
    "        return 1 / np.log(self.num_classes)\n",
    "\n",
    "# not used in current implementation, but important for testing?\n",
    "class MLMSubTask(SubTask):\n",
    "    \"\"\"A Masked Language Modelling Subtask.\"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        \"\"\"Initialize a MLMSubTask.\"\"\"\n",
    "        super(MLMSubTask, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def load_data(self) -> Tuple[torch.LongTensor, torch.LongTensor, torch.LongTensor]:\n",
    "        \"\"\"Load the data of a MLMSubTask.\"\"\"\n",
    "        df = pd.read_csv(self.filename)\n",
    "        X = df[self.src_col]\n",
    "        tokenized_inputs = tokenizer(X.to_list(), padding=\"max_length\", truncation=True, max_length=MAX_LENGTH)\n",
    "        X = torch.LongTensor(tokenized_inputs.get(\"input_ids\"))\n",
    "        attention_masks = tokenized_inputs.get(\"attention_mask\")\n",
    "\n",
    "        MASK_TOKEN = tokenizer.mask_token_id\n",
    "        SEP_TOKEN = tokenizer.sep_token_id\n",
    "        CLS_TOKEN = tokenizer.cls_token_id\n",
    "        PAD_TOKEN = tokenizer.pad_token_id\n",
    "\n",
    "        Y = X.clone()\n",
    "        rand = torch.rand(X.shape)\n",
    "        masking_mask = (rand < 0.15) * (X != SEP_TOKEN) * (X != CLS_TOKEN) * (X != PAD_TOKEN)\n",
    "        X[masking_mask] = MASK_TOKEN\n",
    "        Y[~masking_mask] = -100\n",
    "        return torch.LongTensor(X), torch.LongTensor(Y), torch.LongTensor(attention_masks)\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"Represent a MLM Subtask.\"\"\"\n",
    "        return \"Masked Language Modelling\"\n",
    "\n",
    "    def get_scaling_weight(self):\n",
    "        \"\"\"Get the weights for imbalanced classes.\"\"\"\n",
    "        return 1 / np.log(len(tokenizer))"
   ],
   "id": "6de59d01de66e1ef",
   "outputs": [],
   "execution_count": 276
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:50:17.596200Z",
     "start_time": "2024-12-09T16:50:17.585414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"Dataset handling module for MTL model.\n",
    "\n",
    "This module provides dataset classes for handling different types of data loading\n",
    "and batch generation for the MTL training process.\n",
    "\"\"\"\n",
    "\n",
    "from typing import List, Dict, Iterator, Tuple, Optional\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict\n",
    "\n",
    "from media_bias_detection.utils.logger import general_logger\n",
    "from media_bias_detection.utils.enums import Split\n",
    "from media_bias_detection.utils.common import set_random_seed\n",
    "\n",
    "@dataclass\n",
    "class BatchData:\n",
    "    \"\"\"Container for batch data.\n",
    "\n",
    "    Attributes:\n",
    "        input_ids: Token IDs from tokenizer\n",
    "        attention_mask: Attention mask for padding\n",
    "        labels: Target labels\n",
    "        subtask_id: ID of the subtask this batch belongs to\n",
    "    \"\"\"\n",
    "    input_ids: torch.Tensor\n",
    "    attention_mask: torch.Tensor\n",
    "    labels: torch.Tensor\n",
    "    subtask_id: int\n",
    "\n",
    "\n",
    "class SubTaskDataset(Dataset):\n",
    "    \"\"\"Dataset class for a single SubTask.\n",
    "\n",
    "    This dataset handles the loading and iteration over data for a specific subtask,\n",
    "    with support for shuffling and automatic reset.\n",
    "\n",
    "    Attributes:\n",
    "        split: The data split (TRAIN/DEV/TEST)\n",
    "        subtask: The subtask this dataset is for\n",
    "        observations: List of indices into the data\n",
    "        _counter: Internal counter for iteration\n",
    "        cache: Optional cache for frequently accessed items\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            subtask: SubTask,\n",
    "            split: Split,\n",
    "            cache_size: int = 100\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize the dataset.\n",
    "\n",
    "        Args:\n",
    "            subtask: SubTask instance containing the data\n",
    "            split: Which data split to use\n",
    "            cache_size: Number of items to keep in memory cache\n",
    "        \"\"\"\n",
    "        general_logger.info(f\"Initializing dataset for subtask {subtask.id} with split {split}\")\n",
    "\n",
    "        if not subtask.processed:\n",
    "            raise RuntimeError(f\"Subtask {subtask.id} must be processed before creating dataset\")\n",
    "\n",
    "        self.split = split\n",
    "        self.subtask = subtask\n",
    "        self.observations: List[int] = []\n",
    "        self._counter: int = 0\n",
    "        self._cache: Dict[int, BatchData] = {}\n",
    "        self._cache_size = cache_size\n",
    "        self._reset()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Get number of items in dataset.\"\"\"\n",
    "        return len(self.observations)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, int]:\n",
    "        \"\"\"Get a single item from the dataset.\n",
    "\n",
    "        Args:\n",
    "            idx: Index of the item to get\n",
    "\n",
    "        Returns:\n",
    "            BatchData containing the item data\n",
    "\n",
    "        Raises:\n",
    "            IndexError: If index is out of bounds\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if self._counter >= len(self.observations):\n",
    "                self._reset()\n",
    "\n",
    "            i = self.observations[self._counter]\n",
    "\n",
    "            # Check cache first\n",
    "            if i in self._cache:\n",
    "                self._counter += 1\n",
    "                return self._cache[i]\n",
    "\n",
    "            # Load and process item\n",
    "            x = self.subtask.get_X(split=self.split)[i]\n",
    "            masks = self.subtask.get_att_mask(split=self.split)[i]\n",
    "            y = self.subtask.get_Y(split=self.split)[i]\n",
    "\n",
    "            batch_data = BatchData(\n",
    "                input_ids=x,\n",
    "                attention_mask=masks,\n",
    "                labels=y,\n",
    "                subtask_id=self.subtask.id\n",
    "            )\n",
    "\n",
    "            # Update cache\n",
    "            if len(self._cache) >= self._cache_size:\n",
    "                # Remove oldest item\n",
    "                del self._cache[next(iter(self._cache))]\n",
    "            self._cache[i] = batch_data\n",
    "\n",
    "            self._counter += 1\n",
    "            return x, masks, y, self.subtask.id\n",
    "\n",
    "        except Exception as e:\n",
    "            general_logger.error(f\"Error retrieving item {idx} from dataset: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _reset(self) -> None:\n",
    "        \"\"\"Reset the dataset state and shuffle observations.\"\"\"\n",
    "        general_logger.info(f\"Resetting dataset for subtask {self.subtask.id}\")\n",
    "        self.observations = [i for i in range(len(self.subtask.get_X(split=self.split)))]\n",
    "        set_random_seed()\n",
    "        np.random.shuffle(self.observations)  # Not a real 'reshuffling' as it will always arrange same.\n",
    "        self._counter = 0\n",
    "        self._cache.clear()\n",
    "\n",
    "\n",
    "class BatchList:\n",
    "    \"\"\"Wrapper around dataloaders for continuous batch generation.\n",
    "\n",
    "    This class provides an infinite stream of batches by automatically resetting\n",
    "    exhausted dataloaders. It includes support for dynamic batch sizing and\n",
    "    memory-efficient data loading.\n",
    "\n",
    "    Attributes:\n",
    "        sub_batch_size: Size of each sub-batch\n",
    "        datasets: Mapping of subtask IDs to datasets\n",
    "        dataloaders: Mapping of subtask IDs to dataloaders\n",
    "        iter_dataloaders: Mapping of subtask IDs to dataloader iterators\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            subtask_list: List[SubTask],\n",
    "            sub_batch_size: int,\n",
    "            split: Split = Split.TRAIN,\n",
    "            num_workers: int = 0,\n",
    "            pin_memory: bool = True\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize BatchList.\n",
    "\n",
    "        Args:\n",
    "            subtask_list: List of subtasks to create batches for\n",
    "            sub_batch_size: Size of each sub-batch\n",
    "            split: Which data split to use\n",
    "            num_workers: Number of worker processes for data loading\n",
    "            pin_memory: Whether to pin memory in GPU training\n",
    "        \"\"\"\n",
    "        general_logger.info(\n",
    "            f\"Creating BatchList with {len(subtask_list)} subtasks, \"\n",
    "            f\"batch size {sub_batch_size}\"\n",
    "        )\n",
    "\n",
    "        self.sub_batch_size = sub_batch_size\n",
    "        self.split = split\n",
    "\n",
    "        # Initialize datasets and dataloaders\n",
    "        self.datasets = {\n",
    "            str(st.id): SubTaskDataset(subtask=st, split=split)\n",
    "            for st in subtask_list\n",
    "        }\n",
    "\n",
    "        self.dataloaders = {\n",
    "            st_id: DataLoader(\n",
    "                dataset,\n",
    "                batch_size=self.sub_batch_size,\n",
    "                num_workers=num_workers,\n",
    "                pin_memory=pin_memory\n",
    "            )\n",
    "            for st_id, dataset in self.datasets.items()\n",
    "        }\n",
    "\n",
    "        self.iter_dataloaders = {\n",
    "            st_id: iter(dl)\n",
    "            for st_id, dl in self.dataloaders.items()\n",
    "        }\n",
    "\n",
    "        # Statistics tracking\n",
    "        self._batch_counts = defaultdict(int)\n",
    "\n",
    "    def __next__(self) -> List[BatchData]:\n",
    "        \"\"\"Get next batch of sub-batches.\n",
    "\n",
    "        Returns:\n",
    "            List of BatchData, one for each task\n",
    "\n",
    "        Raises:\n",
    "            RuntimeError: If batch generation fails\n",
    "        \"\"\"\n",
    "        try:\n",
    "            data = []\n",
    "            items = list(self.iter_dataloaders.items())\n",
    "            random.shuffle(items)\n",
    "\n",
    "            for st_id, dl in items:\n",
    "                try:\n",
    "                    batch = next(dl)\n",
    "                except StopIteration:\n",
    "                    # Reset iterator and try again\n",
    "                    self.iter_dataloaders[st_id] = iter(self.dataloaders[st_id])\n",
    "                    batch = next(self.iter_dataloaders[st_id])\n",
    "\n",
    "                data.append(batch)\n",
    "                self._batch_counts[st_id] += 1\n",
    "\n",
    "            general_logger.debug(f\"Generated batch with {len(data)} sub-batches\")\n",
    "            return data\n",
    "\n",
    "        except Exception as e:\n",
    "            general_logger.error(f\"Error generating batch: {str(e)}\")\n",
    "            raise RuntimeError(f\"Batch generation failed: {str(e)}\")\n",
    "\n",
    "    def _reset(self):\n",
    "        \"\"\"Reset this BatchListEvalTest.\"\"\"\n",
    "        self.iter_dataloaders = {f\"{st_id}\": iter(dl) for st_id, dl in self.dataloaders.items()}\n",
    "\n",
    "\n",
    "class BatchListEvalTest:\n",
    "    \"\"\"A BatchListEvalTest is a wrapper around dataloaders for each subtask.\"\"\"\n",
    "\n",
    "    def __init__(self, subtask_list: List[SubTask], sub_batch_size, split=Split.TRAIN):\n",
    "        self.sub_batch_size = sub_batch_size\n",
    "        self.datasets = {f\"{st.id}\": SubTaskDataset(subtask=st, split=split) for st in subtask_list}\n",
    "        self.dataloaders = {\n",
    "            f\"{st_id}\": DataLoader(ds, batch_size=self.sub_batch_size) for st_id, ds in self.datasets.items()\n",
    "        }\n",
    "        self.iter_dataloaders = {f\"{st_id}\": iter(dl) for st_id, dl in self.dataloaders.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return min(len(dl) for dl in self.dataloaders.values())\n",
    "\n",
    "    def _reset(self): # Add this method matching the original\n",
    "        self.iter_dataloaders = {f\"{st_id}\": iter(dl) for st_id, dl in self.dataloaders.items()}"
   ],
   "id": "a4d50837491e4497",
   "outputs": [],
   "execution_count": 277
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:50:21.895165Z",
     "start_time": "2024-12-09T16:50:21.880311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"Data initialization and task definitions for MTL model.\"\"\"\n",
    "\n",
    "from typing import List\n",
    "import itertools\n",
    "\n",
    "from media_bias_detection.utils.logger import general_logger\n",
    "\n",
    "\n",
    "# initializing the sub-tasks I want to use\n",
    "st_1_cw_hard_03 = ClassificationSubTask(\n",
    "task_id=3,\n",
    "filename=\"03_CW_HARD/preprocessed.csv\",\n",
    "id=300001)\n",
    "st_1_me_too_ma_108 = MultiLabelClassificationSubTask(\n",
    "num_classes=2,\n",
    "num_labels=2,\n",
    "task_id=108,\n",
    "filename=\"108_MeTooMA/preprocessed.csv\",\n",
    "id=10801,\n",
    "tgt_cols_list=[\"hate_speech_label\", \"sarcasm_label\"],\n",
    ")\n",
    "st_1_mdgender_116 = ClassificationSubTask(\n",
    "task_id=116,\n",
    "id=11601,\n",
    "filename=\"116_MDGender/preprocessed.csv\",\n",
    "num_classes=6\n",
    ")\n",
    "st_1_mpqa_103 = ClassificationSubTask(\n",
    "task_id=103,\n",
    "id=10301,\n",
    "filename=\"103_MPQA/preprocessed.csv\")\n",
    "st_1_stereotype_109 = ClassificationSubTask(\n",
    "task_id=109,\n",
    "id=10901,\n",
    "filename=\"109_stereotype/preprocessed.csv\")\n",
    "st_2_stereotype_109 = MultiLabelClassificationSubTask(\n",
    "task_id=109,\n",
    "id=10902,\n",
    "filename=\"109_stereotype/preprocessed.csv\",\n",
    "tgt_cols_list=[\"stereotype_explicit_label\", \"stereotype_explicit_label\"],\n",
    "num_classes=2,\n",
    "num_labels=2,\n",
    ")\n",
    "st_1_good_news_everyone_42 = POSSubTask(\n",
    "tgt_cols_list=[\"cue_pos\"],\n",
    "task_id=42,\n",
    "id=42001,\n",
    "filename=\"42_GoodNewsEveryone/preprocessed.csv\"\n",
    ")\n",
    "st_2_good_news_everyone_42 = POSSubTask(\n",
    "tgt_cols_list=[\"experiencer_pos\"],\n",
    "task_id=42,\n",
    "id=42002,\n",
    "filename=\"42_GoodNewsEveryone/preprocessed.csv\",\n",
    ")\n",
    "st_1_pheme_12 = ClassificationSubTask(\n",
    "task_id=12,\n",
    "id=12001,\n",
    "filename=\"12_PHEME/preprocessed.csv\")\n",
    "st_2_pheme_12 = ClassificationSubTask(\n",
    "task_id=12,\n",
    "id=12002,\n",
    "filename=\"12_PHEME/preprocessed.csv\",\n",
    "tgt_cols_list=[\"veracity_label\"],\n",
    "num_classes=3,\n",
    ")\n",
    "st_1_babe_10 = ClassificationSubTask(\n",
    "task_id=10,\n",
    "id=10001,\n",
    "filename=\"10_BABE/preprocessed.csv\",\n",
    "num_classes=2)\n",
    "st_2_babe_10 = POSSubTask(\n",
    "task_id=10,\n",
    "id=10002,\n",
    "filename=\"10_BABE/preprocessed.csv\",\n",
    "tgt_cols_list=[\"biased_words\"])\n",
    "st_1_gwsd_128 = ClassificationSubTask(\n",
    "task_id=128,\n",
    "num_classes=3,\n",
    "filename=\"128_GWSD/preprocessed.csv\",\n",
    "id=12801)\n",
    "\n",
    "# Tasks\n",
    "cw_hard_03 = Task(task_id=3, subtasks_list=[st_1_cw_hard_03])\n",
    "babe_10 = Task(task_id=10, subtasks_list=[st_1_babe_10, st_2_babe_10])\n",
    "me_too_ma_108 = Task(task_id=108, subtasks_list=[st_1_me_too_ma_108])\n",
    "mdgender_116 = Task(task_id=116, subtasks_list=[st_1_mdgender_116])\n",
    "pheme_12 = Task(task_id=12, subtasks_list=[st_2_pheme_12, st_1_pheme_12])\n",
    "mpqa_103 = Task(task_id=103, subtasks_list=[st_1_mpqa_103])\n",
    "stereotype_109 = Task(task_id=109, subtasks_list=[st_1_stereotype_109,\n",
    "                                              st_2_stereotype_109])\n",
    "good_news_everyone_42 = Task(task_id=42,\n",
    "                         subtasks_list=[st_1_good_news_everyone_42,\n",
    "                                        st_2_good_news_everyone_42])\n",
    "gwsd_128 = Task(task_id=128, subtasks_list=[st_1_gwsd_128])\n",
    "\n",
    "\n",
    "# MBIB ###\n",
    "# st_linguistic = ClassificationSubTask(task_id=11111, id=11111, filename=\"mbib_linguistic/preprocessed.csv\", num_classes=2)\n",
    "# mbib_lingustic = Task(task_id=11111, subtasks_list=[st_linguistic])\n",
    "\n",
    "# Create task object\n",
    "all_tasks = [\n",
    "babe_10,\n",
    "cw_hard_03,\n",
    "me_too_ma_108,\n",
    "pheme_12,\n",
    "mdgender_116,\n",
    "mpqa_103,\n",
    "stereotype_109,\n",
    "good_news_everyone_42,\n",
    "gwsd_128,\n",
    "]\n",
    "\n",
    "# Get all subtasks\n",
    "all_subtasks = list(itertools.chain.from_iterable(t.subtasks_list for t in all_tasks))\n",
    "\n",
    "# Task families\n",
    "media_bias = [babe_10]\n",
    "subjective_bias = [cw_hard_03]\n",
    "hate_speech = [me_too_ma_108]\n",
    "gender_bias = [mdgender_116]\n",
    "sentiment_analysis = [mpqa_103]\n",
    "fake_news = [pheme_12]\n",
    "group_bias = [stereotype_109]\n",
    "emotionality = [good_news_everyone_42]\n",
    "stance_detection = [gwsd_128]\n",
    "#mlm = [mlm_0]"
   ],
   "id": "6b35e68946eadf4a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-12-09 17:50:21,884: INFO: 1312152763: Initialized SubTask 300001 for task 3 using file datasets/03_CW_HARD/preprocessed.csv]\n",
      "[2024-12-09 17:50:21,886: INFO: 1312152763: Initialized SubTask 10801 for task 108 using file datasets/108_MeTooMA/preprocessed.csv]\n",
      "MultiClass Subtask 10801:\n",
      "Num classes: 2, Num labels: 2\n",
      "[2024-12-09 17:50:21,887: INFO: 1312152763: Initialized SubTask 11601 for task 116 using file datasets/116_MDGender/preprocessed.csv]\n",
      "[2024-12-09 17:50:21,888: INFO: 1312152763: Initialized SubTask 10301 for task 103 using file datasets/103_MPQA/preprocessed.csv]\n",
      "[2024-12-09 17:50:21,889: INFO: 1312152763: Initialized SubTask 10901 for task 109 using file datasets/109_stereotype/preprocessed.csv]\n",
      "[2024-12-09 17:50:21,890: INFO: 1312152763: Initialized SubTask 10902 for task 109 using file datasets/109_stereotype/preprocessed.csv]\n",
      "MultiClass Subtask 10902:\n",
      "Num classes: 2, Num labels: 2\n",
      "[2024-12-09 17:50:21,891: INFO: 1312152763: Initialized SubTask 42001 for task 42 using file datasets/42_GoodNewsEveryone/preprocessed.csv]\n",
      "[2024-12-09 17:50:21,892: INFO: 1312152763: Initialized SubTask 42002 for task 42 using file datasets/42_GoodNewsEveryone/preprocessed.csv]\n",
      "[2024-12-09 17:50:21,892: INFO: 1312152763: Initialized SubTask 12001 for task 12 using file datasets/12_PHEME/preprocessed.csv]\n",
      "[2024-12-09 17:50:21,892: INFO: 1312152763: Initialized SubTask 12002 for task 12 using file datasets/12_PHEME/preprocessed.csv]\n",
      "[2024-12-09 17:50:21,893: INFO: 1312152763: Initialized SubTask 10001 for task 10 using file datasets/10_BABE/preprocessed.csv]\n",
      "[2024-12-09 17:50:21,893: INFO: 1312152763: Initialized SubTask 10002 for task 10 using file datasets/10_BABE/preprocessed.csv]\n",
      "[2024-12-09 17:50:21,893: INFO: 1312152763: Initialized SubTask 12801 for task 128 using file datasets/128_GWSD/preprocessed.csv]\n"
     ]
    }
   ],
   "execution_count": 278
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Building the Model\n",
    "After initializing the datasets I want to use in the last step, I now build the model:\n",
    "- The backbone is changes to DistilBERT as it is a smaller model and therefore faster to train.\n",
    "- For each task a specific model head is needed to fulfill the task. For this a head factory is used to decide which head to use for the specific task type.\n",
    "- Apart from that, the model needs a GradsWrapper to get and set the gradients of the weights and biases of all trainable layers.\n",
    "- In the model factory the model is then instantiated by combining the backbone with the different model heads for the different tasks."
   ],
   "id": "a4e6c80fbf45a85d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:51:47.861474Z",
     "start_time": "2024-12-09T16:51:47.847934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from helper classes the accumuator classes\n",
    "\"\"\"Module for gradient accumulation and manipulation.\"\"\"\n",
    "\n",
    "from typing import Dict\n",
    "import copy\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from media_bias_detection.utils.logger import general_logger\n",
    "from media_bias_detection.utils.common import rsetattr\n",
    "\n",
    "\n",
    "class AccumulatorError(Exception):\n",
    "    \"\"\"Custom exception for accumulator-related errors.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class Accumulator:\n",
    "    \"\"\"Abstract Accumulator for gradient handling.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize abstract accumulator.\"\"\"\n",
    "        if type(self) == Accumulator:\n",
    "            raise RuntimeError(\"Abstract class <Accumulator> must not be instantiated.\")\n",
    "        self.gradients = None\n",
    "        self.n = 0\n",
    "\n",
    "    def update(self, gradients: Dict[str, torch.Tensor], weight: float = 1.0) -> None:\n",
    "        \"\"\"Update gradient values (must be implemented by concrete classes).\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_avg_gradients(self) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"Return gradients normalized across 0-axis.\"\"\"\n",
    "        try:\n",
    "            if not self.gradients:\n",
    "                raise AccumulatorError(\"No gradients available\")\n",
    "\n",
    "            out_gradients = copy.deepcopy(self.gradients)\n",
    "            for k, v in self.gradients.items():\n",
    "                out_gradients[k] /= self.n\n",
    "                out_gradients[k] = out_gradients[k].squeeze(dim=0)\n",
    "            return out_gradients\n",
    "        except Exception as e:\n",
    "            raise AccumulatorError(f\"Failed to get average gradients: {str(e)}\")\n",
    "\n",
    "    def get_gradients(self) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"Return raw gradients.\"\"\"\n",
    "        if not self.gradients:\n",
    "            raise AccumulatorError(\"No gradients available\")\n",
    "        return self.gradients\n",
    "\n",
    "\n",
    "class StackedAccumulator(Accumulator):\n",
    "    \"\"\"Accumulator that stacks gradients along 0-axis.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize StackedAccumulator.\"\"\"\n",
    "        try:\n",
    "            super().__init__()\n",
    "            general_logger.debug(\"Initialized StackedAccumulator\")\n",
    "        except Exception as e:\n",
    "            raise AccumulatorError(f\"Failed to initialize StackedAccumulator: {str(e)}\")\n",
    "\n",
    "    def update(self, gradients: Dict[str, torch.Tensor], weight: float = 1.0) -> None:\n",
    "        \"\"\"Update by concatenating new gradients along 0-axis.\"\"\"\n",
    "        try:\n",
    "            if not self.gradients:\n",
    "                self.gradients = gradients\n",
    "                # Unsqueeze all gradients for later concatenation\n",
    "                for k, v in self.gradients.items():\n",
    "                    self.gradients[k] = self.gradients[k].unsqueeze(dim=0) * weight\n",
    "            else:\n",
    "                for k, v in self.gradients.items():\n",
    "                    new_value = gradients[k].unsqueeze(dim=0) * weight\n",
    "                    self.gradients[k] = torch.cat((v, new_value), dim=0)\n",
    "            self.n += 1\n",
    "        except Exception as e:\n",
    "            raise AccumulatorError(f\"Failed to update stacked gradients: {str(e)}\")\n",
    "\n",
    "    def set_gradients(self, gradients: Dict[str, torch.Tensor]) -> None:\n",
    "        \"\"\"Set gradients directly.\"\"\"\n",
    "        try:\n",
    "            for k, v in self.gradients.items():\n",
    "                self.gradients[k] = gradients[k].unsqueeze(dim=0)\n",
    "        except Exception as e:\n",
    "            raise AccumulatorError(f\"Failed to set gradients: {str(e)}\")\n",
    "\n",
    "\n",
    "class RunningSumAccumulator(Accumulator):\n",
    "    \"\"\"Accumulator that maintains running sum of gradients.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize RunningSumAccumulator.\"\"\"\n",
    "        try:\n",
    "            super().__init__()\n",
    "            general_logger.debug(\"Initialized RunningSumAccumulator\")\n",
    "        except Exception as e:\n",
    "            raise AccumulatorError(f\"Failed to initialize RunningSumAccumulator: {str(e)}\")\n",
    "\n",
    "    def update(self, gradients: Dict[str, torch.Tensor], weight: float = 1.0) -> None:\n",
    "        \"\"\"Update by summing gradients along 0-axis.\"\"\"\n",
    "        try:\n",
    "            if not self.gradients:\n",
    "                self.gradients = gradients\n",
    "                # Unsqueeze all gradients for later addition\n",
    "                for k, v in self.gradients.items():\n",
    "                    self.gradients[k] = self.gradients[k].unsqueeze(dim=0) * weight\n",
    "            else:\n",
    "                for k, v in self.gradients.items():\n",
    "                    new_value = gradients[k].unsqueeze(dim=0) * weight\n",
    "                    self.gradients[k] = torch.add(v, new_value)\n",
    "            self.n += 1\n",
    "        except Exception as e:\n",
    "            raise AccumulatorError(f\"Failed to update running sum gradients: {str(e)}\")"
   ],
   "id": "63d4fa7d68d9b2b6",
   "outputs": [],
   "execution_count": 279
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:51:48.361388Z",
     "start_time": "2024-12-09T16:51:48.357717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GradsWrapper(nn.Module):\n",
    "    \"\"\"Wrapper for getting/setting gradients of trainable layers.\"\"\"\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        \"\"\"Initialize GradsWrapper.\"\"\"\n",
    "        if type(self) == GradsWrapper:\n",
    "            raise RuntimeError(\"Abstract class <GradsWrapper> must not be instantiated.\")\n",
    "        super().__init__()\n",
    "        general_logger.debug(\"Initialized GradsWrapper\")\n",
    "\n",
    "    def get_grads(self) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"Get gradients of weights and biases for all trainable layers.\"\"\"\n",
    "        try:\n",
    "            return {\n",
    "                k: v.grad.clone() if v.grad is not None else None \n",
    "                for k, v in dict(self.named_parameters()).items()\n",
    "            }\n",
    "        except Exception as e:\n",
    "            raise AccumulatorError(f\"Failed to get gradients: {str(e)}\")\n",
    "\n",
    "    def set_grads(self, grads: Dict[str, torch.Tensor]) -> None:\n",
    "        \"\"\"Set gradients of weights and biases for all trainable layers.\"\"\"\n",
    "        try:\n",
    "            for k, v in grads.items():\n",
    "                rsetattr(self, f\"{k}.grad\", v)\n",
    "        except Exception as e:\n",
    "            raise AccumulatorError(f\"Failed to set gradients: {str(e)}\")\n"
   ],
   "id": "619122f8424460d4",
   "outputs": [],
   "execution_count": 280
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:51:48.900572Z",
     "start_time": "2024-12-09T16:51:48.890559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"Module for combining potentially conflicting gradients with error handling.\"\"\"\n",
    "\n",
    "import random\n",
    "from typing import Dict, Optional\n",
    "import torch\n",
    "\n",
    "from media_bias_detection.utils.logger import general_logger\n",
    "from media_bias_detection.utils.enums import AggregationMethod\n",
    "\n",
    "\n",
    "class GradientError(Exception):\n",
    "    \"\"\"Custom exception for gradient-related errors.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class GradientAggregator:\n",
    "    \"\"\"Aggregator class for combining possibly conflicting gradients into one 'optimal' grad.\"\"\"\n",
    "\n",
    "    def __init__(self, aggregation_method: AggregationMethod = AggregationMethod.MEAN):\n",
    "        try:\n",
    "            self.aggregation_method = aggregation_method\n",
    "            self.accumulator = (\n",
    "                RunningSumAccumulator() if aggregation_method == AggregationMethod.MEAN else StackedAccumulator()\n",
    "            )\n",
    "            self._conflicting_gradient_count = 0\n",
    "            self._nonconflicting_gradient_count = 0\n",
    "            general_logger.info(f\"Initialized GradientAggregator with {aggregation_method}\")\n",
    "        except Exception as e:\n",
    "            raise GradientError(f\"Failed to initialize GradientAggregator: {str(e)}\")\n",
    "\n",
    "    def reset_accumulator(self) -> None:\n",
    "        try:\n",
    "            self.accumulator = (\n",
    "                RunningSumAccumulator() if self.aggregation_method == AggregationMethod.MEAN else StackedAccumulator()\n",
    "            )\n",
    "            general_logger.debug(\"Reset gradient accumulator\")\n",
    "        except Exception as e:\n",
    "            raise GradientError(f\"Failed to reset accumulator: {str(e)}\")\n",
    "\n",
    "    def find_nonconflicting_grad(self, grad_tensor: torch.tensor) -> torch.tensor:\n",
    "        try:\n",
    "            if self.aggregation_method == AggregationMethod.PCGRAD:\n",
    "                return self.pcgrad(grad_tensor).mean(dim=0)\n",
    "            elif self.aggregation_method == AggregationMethod.PCGRAD_ONLINE:\n",
    "                assert len(grad_tensor) == 2\n",
    "                return self.pcgrad_online(grad_tensor)\n",
    "            else:\n",
    "                raise GradientError(f\"Unsupported aggregation method: {self.aggregation_method}\")\n",
    "        except Exception as e:\n",
    "            raise GradientError(f\"Failed to find nonconflicting gradient: {str(e)}\")\n",
    "\n",
    "    def aggregate_gradients(self) -> Dict[str, torch.tensor]:\n",
    "        try:\n",
    "            conflicting_grads = self.accumulator.get_gradients()\n",
    "            length = len(conflicting_grads[list(conflicting_grads.keys())[0]])\n",
    "\n",
    "            if (self.aggregation_method == AggregationMethod.PCGRAD_ONLINE\n",
    "                    or self.aggregation_method == AggregationMethod.MEAN):\n",
    "                assert length == 1\n",
    "                return self.accumulator.get_avg_gradients()\n",
    "\n",
    "            elif self.aggregation_method == AggregationMethod.PCGRAD:\n",
    "                conflicting_grads = [{k: v[i, ...] for k, v in conflicting_grads.items()} for i in range(length)]\n",
    "                final_grad: Dict[str, torch.Tensor] = {}\n",
    "\n",
    "                if len(conflicting_grads) == 1:\n",
    "                    return conflicting_grads[0]\n",
    "\n",
    "                keys = list(conflicting_grads[0].keys())\n",
    "                for layer_key in keys:\n",
    "                    list_of_st_grads = [st_grad[layer_key] for st_grad in conflicting_grads]\n",
    "                    final_grad.update({layer_key: self.find_nonconflicting_grad(torch.stack(list_of_st_grads, dim=0))})\n",
    "\n",
    "                return final_grad\n",
    "            else:\n",
    "                raise GradientError(f\"Unsupported aggregation method: {self.aggregation_method}\")\n",
    "        except Exception as e:\n",
    "            raise GradientError(f\"Gradient aggregation failed: {str(e)}\")\n",
    "\n",
    "    def pcgrad(self, grad_tensor: torch.tensor) -> torch.tensor:\n",
    "        try:\n",
    "            pc_grads, num_of_tasks = grad_tensor.clone(), len(grad_tensor)\n",
    "            original_shape = grad_tensor.shape\n",
    "            \n",
    "            pc_grads = pc_grads.view(num_of_tasks, -1)\n",
    "            grad_tensor = grad_tensor.view(num_of_tasks, -1)\n",
    "\n",
    "            for g_i in range(num_of_tasks):\n",
    "                task_index = list(range(num_of_tasks))\n",
    "                random.shuffle(task_index)\n",
    "                for g_j in task_index:\n",
    "                    dot_product = pc_grads[g_i].dot(grad_tensor[g_j])\n",
    "                    if dot_product < 0:\n",
    "                        pc_grads[g_i] -= (dot_product / (grad_tensor[g_j].norm() ** 2)) * grad_tensor[g_j]\n",
    "                        self._conflicting_gradient_count += 1\n",
    "                    else:\n",
    "                        self._nonconflicting_gradient_count += 1\n",
    "            return pc_grads.view(original_shape)\n",
    "        except Exception as e:\n",
    "            raise GradientError(f\"PCGrad processing failed: {str(e)}\")\n",
    "\n",
    "    def pcgrad_online(self, grad_tensor: torch.tensor) -> torch.tensor:\n",
    "        try:\n",
    "            assert len(grad_tensor) == 2\n",
    "            p = grad_tensor[0].view(-1)\n",
    "            g = grad_tensor[-1].view(-1)\n",
    "\n",
    "            dot_product = p.dot(g)\n",
    "            if dot_product < 0:\n",
    "                p = p - (dot_product / (g.norm() ** 2)) * g\n",
    "                self._conflicting_gradient_count += 1\n",
    "            else:\n",
    "                self._nonconflicting_gradient_count += 1\n",
    "\n",
    "            p += g\n",
    "            return p.view(grad_tensor[0].shape)\n",
    "        except Exception as e:\n",
    "            raise GradientError(f\"Online PCGrad processing failed: {str(e)}\")\n",
    "\n",
    "    def aggregate_gradients_online(self) -> Dict[str, torch.tensor]:\n",
    "        try:\n",
    "            conflicting_grads = self.accumulator.get_gradients()\n",
    "            length = len(conflicting_grads[list(conflicting_grads.keys())[0]])\n",
    "            conflicting_grads = [{k: v[i, ...] for k, v in conflicting_grads.items()} for i in range(length)]\n",
    "            current_overall_grad: Dict[str, torch.Tensor] = {}\n",
    "\n",
    "            if length == 1:\n",
    "                return conflicting_grads[0]\n",
    "            elif length == 2:\n",
    "                keys = list(conflicting_grads[0].keys())\n",
    "                for layer_key in keys:\n",
    "                    list_of_st_grads = [st_grad[layer_key] for st_grad in conflicting_grads]\n",
    "                    current_overall_grad.update(\n",
    "                        {layer_key: self.find_nonconflicting_grad(torch.stack(list_of_st_grads, dim=0))}\n",
    "                    )\n",
    "                return current_overall_grad\n",
    "            else:\n",
    "                raise GradientError(\"Invalid gradient length for online aggregation\")\n",
    "        except Exception as e:\n",
    "            raise GradientError(f\"Online gradient aggregation failed: {str(e)}\")\n",
    "\n",
    "    def update(self, gradients: Dict[str, torch.tensor], scaling_weight: float) -> None:\n",
    "        try:\n",
    "            self.accumulator.update(gradients=gradients, weight=scaling_weight)\n",
    "            if self.aggregation_method == AggregationMethod.PCGRAD_ONLINE:\n",
    "                self.accumulator.set_gradients(gradients=self.aggregate_gradients_online())\n",
    "        except Exception as e:\n",
    "            raise GradientError(f\"Failed to update gradients: {str(e)}\")\n",
    "\n",
    "    def get_conflicting_gradients_ratio(self) -> Optional[float]:\n",
    "        try:\n",
    "            if self.aggregation_method == AggregationMethod.MEAN:\n",
    "                raise GradientError(\"Cannot get conflict ratio for MEAN method\")\n",
    "            if self._conflicting_gradient_count + self._nonconflicting_gradient_count == 0:\n",
    "                raise GradientError(\"No gradients processed yet\")\n",
    "            return self._conflicting_gradient_count / (\n",
    "                self._conflicting_gradient_count + self._nonconflicting_gradient_count\n",
    "            )\n",
    "        except Exception as e:\n",
    "            raise GradientError(f\"Failed to calculate gradient conflict ratio: {str(e)}\")"
   ],
   "id": "dd4a4dd0c7df6c22",
   "outputs": [],
   "execution_count": 281
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:51:49.455950Z",
     "start_time": "2024-12-09T16:51:49.452656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"Backbone model module providing the shared language model.\"\"\"\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import DistilBertModel\n",
    "from media_bias_detection.utils.logger import general_logger\n",
    "\n",
    "class BackboneLM(GradsWrapper):\n",
    "    \"\"\"Language model backbone shared across all tasks.\n",
    "\n",
    "    This class wraps the pretrained DistilBERT model and handles\n",
    "    gradient manipulation for the shared parameters.\n",
    "\n",
    "    Attributes:\n",
    "        backbone: The underlying DistilBERT model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pretrained_path: str = None):\n",
    "        \"\"\"Initialize the backbone model.\n",
    "\n",
    "        Args:\n",
    "            pretrained_path: Optional path to pretrained weights\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        try:\n",
    "            general_logger.info(\"Initializing backbone language model\")\n",
    "            self.backbone = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "            if pretrained_path:\n",
    "                self.load_pretrained(pretrained_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            general_logger.error(f\"Failed to initialize backbone: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def load_pretrained(self, path: str) -> None:\n",
    "        \"\"\"Load pretrained weights.\n",
    "\n",
    "        Args:\n",
    "            path: Path to pretrained weights\n",
    "\n",
    "        Raises:\n",
    "            RuntimeError: If loading fails\n",
    "        \"\"\"\n",
    "        try:\n",
    "            state_dict = torch.load(path)\n",
    "            self.backbone.load_state_dict(state_dict)\n",
    "            general_logger.info(f\"Loaded pretrained weights from {path}\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Failed to load pretrained weights: {str(e)}\")"
   ],
   "id": "21c1ea37f8afd8d2",
   "outputs": [],
   "execution_count": 282
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:51:49.908503Z",
     "start_time": "2024-12-09T16:51:49.894144Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"Model heads implementation for MTL model.\n",
    "\n",
    "This module contains all task-specific heads and the factory for creating them.\n",
    "Each head implements specific logic for different types of tasks while maintaining\n",
    "consistent interfaces for the MTL architecture.\n",
    "\"\"\"\n",
    "\n",
    "from typing import Dict, Tuple, Optional, Union\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import Accuracy, F1Score, MeanSquaredError, Perplexity, R2Score\n",
    "\n",
    "from media_bias_detection.utils.logger import general_logger\n",
    "from media_bias_detection.utils.common import get_class_weights\n",
    "\n",
    "\n",
    "class HeadError(Exception):\n",
    "    \"\"\"Custom exception for head-related errors.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def HeadFactory(st: SubTask, *args, **kwargs) -> 'BaseHead':\n",
    "    \"\"\"Create appropriate head based on subtask type.\n",
    "\n",
    "    Args:\n",
    "        st: Subtask to create head for\n",
    "        *args, **kwargs: Additional arguments for head initialization\n",
    "\n",
    "    Returns:\n",
    "        Initialized head instance\n",
    "\n",
    "    Raises:\n",
    "        HeadError: If head creation fails or subtask type is unsupported\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if isinstance(st, ClassificationSubTask):\n",
    "            print(f\"Creating ClassificationHead for subtask {st.id}\")\n",
    "            print(f\"num_classes: {st.num_classes}\")\n",
    "            return ClassificationHead(\n",
    "                num_classes=st.num_classes,\n",
    "                class_weights=st.class_weights,\n",
    "                *args,\n",
    "                **kwargs\n",
    "            )\n",
    "        elif isinstance(st, MultiLabelClassificationSubTask):\n",
    "            print(f\"Creating MultiLabelClassificationHead for subtask {st.id}\")\n",
    "            print(f\"num_classes: {st.num_classes}, num_labels: {st.num_labels}\")\n",
    "            return ClassificationHead(\n",
    "                num_classes=st.num_classes,\n",
    "                num_labels=st.num_labels if st.num_labels is not None else 2,\n",
    "                class_weights=st.class_weights,\n",
    "                *args,\n",
    "                **kwargs\n",
    "            )\n",
    "        elif isinstance(st, POSSubTask):\n",
    "            return TokenClassificationHead(\n",
    "                num_classes=st.num_classes,\n",
    "                class_weights=st.class_weights,\n",
    "                *args,\n",
    "                **kwargs\n",
    "            )\n",
    "        elif isinstance(st, RegressionSubTask):\n",
    "            return RegressionHead(*args, **kwargs)\n",
    "        elif isinstance(st, MLMSubTask):\n",
    "            return LanguageModellingHead(*args, **kwargs)\n",
    "        else:\n",
    "            raise HeadError(f\"Unsupported subtask type: {type(st)}\")\n",
    "    except Exception as e:\n",
    "        raise HeadError(f\"Head creation failed: {str(e)}\")\n",
    "\n",
    "\n",
    "class BaseHead(GradsWrapper):\n",
    "    \"\"\"Base class for all model heads.\n",
    "\n",
    "    Attributes:\n",
    "        metrics: Dictionary of metric names to metric instances\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.metrics: Dict = {}\n",
    "\n",
    "    def forward(self, X: torch.Tensor, y: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, Dict]:\n",
    "        \"\"\"Forward pass through the head.\n",
    "\n",
    "        Args:\n",
    "            X: Input features (batch_size, seq_len, hidden_dim)\n",
    "            y: Target labels\n",
    "\n",
    "        Returns:\n",
    "            Tuple of (logits, loss, metric_values)\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class ClassificationHead(BaseHead):\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_dimension: int,\n",
    "            hidden_dimension: int,\n",
    "            dropout_prob: float,\n",
    "            num_classes: int = 2,\n",
    "            num_labels: int = 1,\n",
    "            class_weights: Optional[torch.Tensor] = None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        print(f\"Initializing ClassificationHead\")\n",
    "        print(f\"num_classes: {num_classes}\")\n",
    "        print(f\"num_labels: {num_labels}\")\n",
    "        \n",
    "        # Common layers\n",
    "        self.dense = nn.Linear(input_dimension, hidden_dimension)\n",
    "        self.dropout = nn.Dropout(p=dropout_prob)\n",
    "        self.out_proj = nn.Linear(hidden_dimension, num_classes * num_labels)\n",
    "        \n",
    "        # Store dimensions\n",
    "        self.num_classes = num_classes\n",
    "        self.num_labels = num_labels\n",
    "        \n",
    "        # Use CrossEntropyLoss for both cases\n",
    "        self.loss = nn.CrossEntropyLoss(weight=class_weights)\n",
    "        print(f\"Initializing ClassificationHead with {num_labels} labels\")\n",
    "        # Set up metrics based on task type\n",
    "        if num_labels > 1:  # Multi-label case\n",
    "            self.metrics = {\n",
    "                \"f1\": F1Score(\n",
    "                    num_classes=num_classes,\n",
    "                    num_labels=num_labels,\n",
    "                    task=\"multilabel\",\n",
    "                    average=\"macro\"\n",
    "                ),\n",
    "                \"acc\": Accuracy(\n",
    "                    task=\"multilabel\",\n",
    "                    num_classes=num_classes,\n",
    "                     num_labels=num_labels,\n",
    "                ),\n",
    "            }\n",
    "        else:  # Regular classification case\n",
    "            self.metrics = {\n",
    "                \"f1\": F1Score(\n",
    "                    num_classes=num_classes,\n",
    "                    task=\"binary\" if num_classes == 2 else \"multiclass\",\n",
    "                    average=\"macro\"\n",
    "                ),\n",
    "                \"acc\": Accuracy(\n",
    "                    task=\"binary\" if num_classes == 2 else \"multiclass\",\n",
    "                    num_classes=num_classes,\n",
    "                ),\n",
    "            }\n",
    "\n",
    "    def forward(self, X: torch.Tensor, y: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, Dict]:\n",
    "        try:\n",
    "            batch_size = y.shape[0]\n",
    "            print(f\"Batch size: {batch_size}\")\n",
    "            print(f\"X shape: {X.shape}\")\n",
    "            print(f\"y shape: {y.shape}\")\n",
    "    \n",
    "            # Get CLS token representation\n",
    "            x = X[:, 0, :]  # take <s> token (equiv. to [CLS])\n",
    "            \n",
    "            # Pass through layers\n",
    "            x = self.dropout(x)\n",
    "            x = self.dense(x)\n",
    "            x = torch.tanh(x)\n",
    "            x = self.dropout(x)\n",
    "            logits = self.out_proj(x)\n",
    "    \n",
    "            # Compute loss\n",
    "            loss = self.loss(logits.view(-1, self.num_classes), y.view(-1))\n",
    "            print(f\"Logits shape: {logits.shape}\")\n",
    "            \n",
    "            # Reshape logits based on task type\n",
    "            if self.num_labels > 1:  # Multi-label case\n",
    "                logits = logits.view(batch_size, self.num_labels, self.num_classes)\n",
    "                y = y.view(batch_size, self.num_labels)\n",
    "            else:  # Binary/multiclass case\n",
    "                logits = logits.view(batch_size, self.num_classes)\n",
    "                y = y.view(batch_size)  # Flatten targets\n",
    "    \n",
    "            # Compute loss\n",
    "            loss = self.loss(logits, y)\n",
    "            \n",
    "            # Get predictions in correct shape for metrics\n",
    "            predictions = torch.argmax(logits, dim=-1)  # Use last dimension for class prediction\n",
    "            \n",
    "            # Calculate metrics\n",
    "            metrics = {\n",
    "                name: metric(predictions.cpu(), y.cpu())\n",
    "                for name, metric in self.metrics.items()\n",
    "            }\n",
    "    \n",
    "            return logits, loss, metrics\n",
    "\n",
    "        except Exception as e:\n",
    "            raise HeadError(f\"Classification forward pass failed: {str(e)}\")\n",
    "\n",
    "\n",
    "class TokenClassificationHead(BaseHead):\n",
    "    \"\"\"Head for token-level classification tasks.\n",
    "\n",
    "    Attributes:\n",
    "        dropout: Dropout layer\n",
    "        classifier: Classification layer\n",
    "        num_classes: Number of classes\n",
    "        loss: Loss function\n",
    "        metrics: Dictionary of metrics\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_classes: int,\n",
    "            class_weights: Optional[torch.Tensor],\n",
    "            hidden_dimension: int,\n",
    "            dropout_prob: float,\n",
    "            *args,\n",
    "            **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout_prob)\n",
    "        self.classifier = nn.Linear(hidden_dimension, num_classes)\n",
    "        self.num_classes = num_classes\n",
    "        self.loss = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "        self.metrics = {\n",
    "            \"f1\": F1Score(\n",
    "                num_classes=num_classes,\n",
    "                task=\"multiclass\",\n",
    "                average=\"macro\"\n",
    "            ),\n",
    "            \"acc\": Accuracy(\n",
    "                task=\"multiclass\",\n",
    "                num_classes=num_classes\n",
    "            ),\n",
    "        }\n",
    "\n",
    "        general_logger.info(\n",
    "            f\"Initialized TokenClassificationHead with {num_classes} classes\"\n",
    "        )\n",
    "\n",
    "    def forward(self, X: torch.Tensor, y: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, Dict]:\n",
    "        try:\n",
    "            # Process sequence\n",
    "            sequence_output = self.dropout(X)\n",
    "            logits = self.classifier(sequence_output)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = self.loss(logits.view(-1, self.num_classes), y.view(-1))\n",
    "\n",
    "            # Mask padding tokens for metrics\n",
    "            mask = torch.where(y != -100, 1, 0)\n",
    "            logits = torch.masked_select(\n",
    "                logits,\n",
    "                mask.unsqueeze(-1).expand(logits.size()) == 1\n",
    "            )\n",
    "            y = torch.masked_select(y, mask == 1)\n",
    "            logits = logits.view(y.shape[0], self.num_classes)\n",
    "\n",
    "            # calculate metrics with predictions instead of logits\n",
    "            predictions = torch.argmax(logits, dim=1)\n",
    "            metrics = {\n",
    "                name: metric(predictions.cpu(), y.cpu())\n",
    "                for name, metric in self.metrics.items()\n",
    "            }\n",
    "\n",
    "            return logits, loss, metrics\n",
    "\n",
    "        except Exception as e:\n",
    "            raise HeadError(f\"Token classification forward pass failed: {str(e)}\")\n",
    "\n",
    "\n",
    "class RegressionHead(BaseHead):\n",
    "    \"\"\"Head for regression tasks.\n",
    "\n",
    "    Attributes:\n",
    "        dense: Dense layer\n",
    "        dropout: Dropout layer\n",
    "        out_proj: Output projection layer\n",
    "        loss: Loss function\n",
    "        metrics: Dictionary of metrics\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_dimension: int,\n",
    "            hidden_dimension: int,\n",
    "            dropout_prob: float\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dense = nn.Linear(input_dimension, hidden_dimension)\n",
    "        self.dropout = nn.Dropout(p=dropout_prob)\n",
    "        self.out_proj = nn.Linear(hidden_dimension, 1)\n",
    "\n",
    "        self.loss = nn.MSELoss()\n",
    "        self.metrics = {\n",
    "            \"R2\": R2Score(),\n",
    "            \"MSE\": MeanSquaredError()\n",
    "        }\n",
    "\n",
    "        general_logger.info(\"Initialized RegressionHead\")\n",
    "\n",
    "    def forward(self, X: torch.Tensor, y: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, Dict]:\n",
    "        try:\n",
    "            # Get CLS token\n",
    "            x = X[:, 0, :]\n",
    "\n",
    "            # Pass through layers\n",
    "            x = self.dropout(x)\n",
    "            x = self.dense(x)\n",
    "            x = torch.tanh(x)\n",
    "            x = self.dropout(x)\n",
    "            logits = self.out_proj(x)\n",
    "\n",
    "            loss = self.loss(logits.squeeze(), y.squeeze())\n",
    "\n",
    "            metrics = {\n",
    "                name: metric(logits.cpu(), y.cpu()).detach()\n",
    "                for name, metric in self.metrics.items()\n",
    "            }\n",
    "\n",
    "            return logits, loss, metrics\n",
    "\n",
    "        except Exception as e:\n",
    "            raise HeadError(f\"Regression forward pass failed: {str(e)}\")\n",
    "\n",
    "\n",
    "class LanguageModellingHead(BaseHead):\n",
    "    \"\"\"Head for masked language modeling tasks.\n",
    "\n",
    "    Attributes:\n",
    "        dense: Dense layer\n",
    "        layer_norm: Layer normalization\n",
    "        decoder: Output decoder\n",
    "        loss: Loss function\n",
    "        metrics: Dictionary of metrics\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_dimension: int,\n",
    "            hidden_dimension: int,\n",
    "            dropout_prob: float\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dense = nn.Linear(input_dimension, hidden_dimension)\n",
    "        self.layer_norm = nn.LayerNorm(hidden_dimension, eps=1e-5)\n",
    "        self.gelu = nn.GELU()\n",
    "\n",
    "        self.decoder = nn.Linear(hidden_dimension, tokenizer.vocab_size)\n",
    "        self.bias = nn.Parameter(torch.zeros(tokenizer.vocab_size))\n",
    "        self.decoder.bias = self.bias\n",
    "\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        self.metrics = {\"perplexity\": Perplexity()}\n",
    "\n",
    "        general_logger.info(\"Initialized LanguageModellingHead\")\n",
    "\n",
    "    def forward(self, X: torch.Tensor, y: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, Dict]:\n",
    "        try:\n",
    "            x = self.dense(X)\n",
    "            x = self.gelu(x)\n",
    "            x = self.layer_norm(x)\n",
    "\n",
    "            logits = self.decoder(x)\n",
    "            loss = self.loss(\n",
    "                logits.view(-1, tokenizer.vocab_size),\n",
    "                y.view(-1)\n",
    "            )\n",
    "\n",
    "            metrics = {\n",
    "                name: metric(logits.cpu(), y.cpu())\n",
    "                for name, metric in self.metrics.items()\n",
    "            }\n",
    "\n",
    "            return logits, loss, metrics\n",
    "\n",
    "        except Exception as e:\n",
    "            raise HeadError(f\"Language modeling forward pass failed: {str(e)}\")"
   ],
   "id": "f3f270de9eb9ea3c",
   "outputs": [],
   "execution_count": 283
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:51:50.121028Z",
     "start_time": "2024-12-09T16:51:50.116265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"Main MTL model implementation.\"\"\"\n",
    "\n",
    "from typing import Dict, Tuple, Optional\n",
    "import torch\n",
    "from torch import nn\n",
    "from typing import List\n",
    "\n",
    "from media_bias_detection.utils.logger import general_logger\n",
    "\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \"\"\"MTL model combining backbone and task-specific heads.\"\"\"\n",
    "\n",
    "    def __init__(self, stl: List, *args, **kwargs):\n",
    "        \"\"\"Initialize model with subtasks list and create task-specific heads.\n",
    "\n",
    "        Args:\n",
    "            stl: List of subtasks to create heads for\n",
    "            *args: Additional positional arguments for heads\n",
    "            **kwargs: Additional keyword arguments for heads\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.stl = stl\n",
    "        self.subtask_id_to_subtask = {int(f\"{st.id}\"): st for st in stl}\n",
    "        # Setup device\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
    "\n",
    "        # Initialize backbone\n",
    "        self.language_model = BackboneLM()\n",
    "        self.language_model.backbone.resize_token_embeddings(len(tokenizer))\n",
    "        # Initialize heads\n",
    "        self.heads = nn.ModuleDict({str(st.id): HeadFactory(st, *args, **kwargs) for st in stl})\n",
    "\n",
    "        # Move model to device\n",
    "        self.to(self.device)\n",
    "        general_logger.info(f\"Initialized model with {len(self.heads)} heads on {self.device}\")\n",
    "\n",
    "    def forward(self, X, attention_masks, Y, st_id):\n",
    "        \"\"\"Pass data through model and task-specific head.\n",
    "\n",
    "        Args:\n",
    "            X: Input tensor\n",
    "            attention_masks: Attention mask tensor\n",
    "            Y: Target tensor\n",
    "            st_id: Subtask ID\n",
    "\n",
    "        Returns:\n",
    "            Tuple of (loss, metrics)\n",
    "        \"\"\"\n",
    "        # Pass through backbone\n",
    "        with torch.set_grad_enabled(self.training):\n",
    "            x_enc = self.language_model.backbone(\n",
    "                input_ids=X,\n",
    "                attention_mask=attention_masks\n",
    "            ).last_hidden_state\n",
    "\n",
    "            # Pass through task-specific head\n",
    "            head = self.heads[str(st_id.item())]\n",
    "            logits, loss, metrics = head(x_enc, Y)\n",
    "\n",
    "            return loss, metrics"
   ],
   "id": "468e13ddef56edb5",
   "outputs": [],
   "execution_count": 284
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:51:50.601888Z",
     "start_time": "2024-12-09T16:51:50.593870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#TO DO: muss mit restlichen modulen abgeglichen werden\n",
    "\n",
    "\"\"\"Module for creating instantiating the appropriate model defined by the task list only.\"\"\"\n",
    "\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "\n",
    "from media_bias_detection.utils.enums import Split\n",
    "\n",
    "def ModelFactory(\n",
    "        task_list: List,\n",
    "        sub_batch_size: int,\n",
    "        eval_batch_size: int,\n",
    "        pretrained_path: str = None,\n",
    "        *args,\n",
    "        **kwargs\n",
    "):\n",
    "    \"\"\"Create model and return it along with dataloaders.\"\"\"\n",
    "    # Get all subtasks from task list\n",
    "    subtask_list = [st for t in task_list for st in t.subtasks_list]\n",
    "\n",
    "    # Verify data is processed\n",
    "    for st in subtask_list:\n",
    "        assert st.processed, \"Data must be loaded at this point.\"\n",
    "\n",
    "    # Create model\n",
    "    model = Model(stl=subtask_list, **kwargs)\n",
    "\n",
    "    if pretrained_path is not None:\n",
    "        model = load_pretrained_weights(model, pretrained_path=pretrained_path)\n",
    "\n",
    "    # Move model to appropriate device\n",
    "    model.to(model.device)\n",
    "\n",
    "    try:\n",
    "        # Create dataloaders with updated classes\n",
    "        batch_list_train = BatchList(\n",
    "            subtask_list=subtask_list,\n",
    "            sub_batch_size=sub_batch_size,\n",
    "            split=Split.TRAIN\n",
    "        )\n",
    "        \n",
    "        batch_list_dev = BatchList(\n",
    "            subtask_list=subtask_list, \n",
    "            sub_batch_size=eval_batch_size,\n",
    "            split=Split.DEV\n",
    "        )\n",
    "        \n",
    "        batch_list_eval = BatchListEvalTest(\n",
    "            subtask_list=subtask_list,\n",
    "            sub_batch_size=sub_batch_size, \n",
    "            split=Split.DEV\n",
    "        )\n",
    "        \n",
    "        batch_list_test = BatchListEvalTest(\n",
    "            subtask_list=subtask_list,\n",
    "            sub_batch_size=sub_batch_size,\n",
    "            split=Split.TEST\n",
    "        )\n",
    "        \n",
    "        return model, batch_list_train, batch_list_dev, batch_list_eval, batch_list_test\n",
    "        \n",
    "    except Exception as e:\n",
    "        general_logger.error(f\"Failed to create model and dataloaders: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def save_head_initializations(model):\n",
    "    \"\"\"Save weight initialization of the head. This method will not be called anymore.\n",
    "     It's only for the initial saving of weight inits for all tasks.\"\"\"\n",
    "    for head_name in model.heads.keys():\n",
    "        torch.save(model.heads[head_name].state_dict(), 'model_files/heads/' + head_name + '_init.pth')\n",
    "\n",
    "\n",
    "def load_head_initializations(model):\n",
    "    \"\"\"Load fixed weight initialization for each head in order to ensure reproducibility.\"\"\"\n",
    "    for head_name in model.heads.keys():\n",
    "        weights_path = 'model_files/heads/' + head_name + '_init.pth'\n",
    "        head_weights = torch.load(weights_path)\n",
    "        model.heads[head_name].load_state_dict(head_weights, strict=True)\n",
    "\n",
    "\n",
    "def load_pretrained_weights(model, pretrained_path):\n",
    "    \"\"\"Load the weights of a pretrained model.\"\"\"\n",
    "    weight_dict = torch.load(pretrained_path)\n",
    "    model.load_state_dict(weight_dict, strict=False)\n",
    "    return model"
   ],
   "id": "5dc74770576b2888",
   "outputs": [],
   "execution_count": 285
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Training the Model\n",
    "\n",
    "For the model training the MAGPIE repository first introduces some helper functions. Since they are specific to the training, I include them into the notebook, instead of using them as a separate module like the other utility functions."
   ],
   "id": "58fc758d8464619"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:51:52.688032Z",
     "start_time": "2024-12-09T16:51:52.679651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"Training utilities module for MTL training.\n",
    "\n",
    "Contains utility classes for:\n",
    "- Logging\n",
    "- Early stopping\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import os\n",
    "import logging\n",
    "\n",
    "from enum import Enum\n",
    "from typing import Dict, List, Any, Optional\n",
    "\n",
    "from media_bias_detection.utils.logger import general_logger\n",
    "from media_bias_detection.utils.enums import Split\n",
    "\n",
    "import wandb\n",
    "\n",
    "\n",
    "\n",
    "class Logger:\n",
    "    \"\"\"Logger to keep track of metrics, losses and artifacts.\"\"\"\n",
    "\n",
    "    def __init__(self, experiment_name: str):\n",
    "        PATH = \"logging/\" + experiment_name\n",
    "        os.makedirs(PATH, exist_ok=True)\n",
    "\n",
    "        self.experiment_logfilename = PATH + \"/train_data.log\"\n",
    "        experiment_logfile_handler = logging.FileHandler(filename=self.experiment_logfilename)\n",
    "        experiment_logfile_formatter = logging.Formatter(fmt=\"%(message)s\")\n",
    "        experiment_logfile_handler.setFormatter(experiment_logfile_formatter)\n",
    "\n",
    "        self.experiment_logger = logging.getLogger(\"experiment_logger\")\n",
    "        self.experiment_logger.addHandler(experiment_logfile_handler)\n",
    "        self.experiment_logger.setLevel(\"INFO\")\n",
    "\n",
    "    def log(self, out: Dict[str, Any]) -> None:\n",
    "        try:\n",
    "            self.experiment_logger.info(out)\n",
    "            wandb.log(out)\n",
    "        except Exception as e:\n",
    "            print(f\"Logging failed: {str(e)}\")\n",
    "\n",
    "\n",
    "class EarlyStoppingMode(Enum):\n",
    "    \"\"\"Mode for early stopping behavior.\"\"\"\n",
    "    HEADS = \"heads\"  # Only stop heads\n",
    "    BACKBONE = \"backbone\"  # Also stop backbone\n",
    "    NONE = \"none\"  # No early stopping\n",
    "\n",
    "\n",
    "class EarlyStopperSingle:\n",
    "    \"\"\"Early stopping tracker for a single model component.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            patience: int,\n",
    "            min_delta: float,\n",
    "            resurrection: bool,\n",
    "            zombie_patience: int = 10\n",
    "    ):\n",
    "        \"\"\"Initialize early stopping tracker.\n",
    "\n",
    "        Args:\n",
    "            patience: How many epochs to wait before stopping\n",
    "            min_delta: Minimum change to count as improvement\n",
    "            resurrection: Whether to allow resurrection\n",
    "            zombie_patience: Patience for zombie state\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.patience_zombie = zombie_patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.counter_zombie = 0\n",
    "        self.min_dev_loss = float('inf')\n",
    "        self.min_dev_loss_zombie = float('inf')\n",
    "        self.resurrection = resurrection\n",
    "\n",
    "    def early_stop(self, dev_loss: float) -> bool:\n",
    "        \"\"\"Check if training should stop.\n",
    "\n",
    "        Args:\n",
    "            dev_loss: Current validation loss\n",
    "\n",
    "        Returns:\n",
    "            Whether to stop training\n",
    "        \"\"\"\n",
    "        if math.isnan(dev_loss):\n",
    "            return False\n",
    "\n",
    "        if dev_loss < self.min_dev_loss:\n",
    "            self.min_dev_loss = dev_loss\n",
    "            self.counter = 0\n",
    "        elif dev_loss > (self.min_dev_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def resurrect(self, dev_loss: float) -> bool:\n",
    "        \"\"\"Check if training should resume.\n",
    "\n",
    "        Args:\n",
    "            dev_loss: Current validation loss\n",
    "\n",
    "        Returns:\n",
    "            Whether to resume training\n",
    "        \"\"\"\n",
    "        if math.isnan(dev_loss) or not self.resurrection:\n",
    "            return False\n",
    "\n",
    "        if dev_loss < self.min_dev_loss_zombie:\n",
    "            self.min_dev_loss_zombie = dev_loss\n",
    "            self.counter_zombie = 0\n",
    "        elif dev_loss > self.min_dev_loss_zombie:\n",
    "            self.counter_zombie += 1\n",
    "            if self.counter_zombie >= self.patience_zombie:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        \"\"\"Reset early stopping state.\"\"\"\n",
    "        self.counter_zombie = 0\n",
    "        self.counter = 0\n",
    "        self.min_dev_loss_zombie = float('inf')\n",
    "        self.min_dev_loss = float('inf')\n",
    "\n",
    "\n",
    "class EarlyStopper:\n",
    "    \"\"\"Container for managing multiple early stoppers.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            st_ids: List[str],\n",
    "            mode: EarlyStoppingMode,\n",
    "            patience: Dict[str, int],\n",
    "            resurrection: bool,\n",
    "            min_delta: float = 0\n",
    "    ):\n",
    "        \"\"\"Initialize early stopping manager.\n",
    "\n",
    "        Args:\n",
    "            st_ids: List of subtask IDs\n",
    "            mode: Early stopping mode\n",
    "            patience: Dictionary of patience values per subtask\n",
    "            resurrection: Whether to allow resurrection\n",
    "            min_delta: Minimum improvement threshold\n",
    "        \"\"\"\n",
    "        self.mode = mode\n",
    "        self.early_stoppers = {\n",
    "            st_id: EarlyStopperSingle(\n",
    "                patience=patience[st_id],\n",
    "                min_delta=min_delta,\n",
    "                resurrection=resurrection\n",
    "            )\n",
    "            for st_id in st_ids\n",
    "        }\n",
    "        general_logger.info(\n",
    "            f\"Initialized early stopping manager with mode {mode}\"\n",
    "        )\n",
    "\n",
    "    def early_stop(self, st_id: str, dev_loss: float) -> bool:\n",
    "        \"\"\"Check if specific task should stop.\"\"\"\n",
    "        return (\n",
    "            False if self.mode == EarlyStoppingMode.NONE\n",
    "            else self.early_stoppers[st_id].early_stop(dev_loss=dev_loss)\n",
    "        )\n",
    "\n",
    "    def resurrect(self, st_id: str, dev_loss: float) -> bool:\n",
    "        \"\"\"Check if specific task should resurrect.\"\"\"\n",
    "        return (\n",
    "            False if self.mode == EarlyStoppingMode.NONE\n",
    "            else self.early_stoppers[st_id].resurrect(dev_loss=dev_loss)\n",
    "        )\n",
    "\n",
    "    def reset_early_stopper(self, st_id: str) -> None:\n",
    "        \"\"\"Reset early stopper for specific task.\"\"\"\n",
    "        self.early_stoppers[st_id].reset()"
   ],
   "id": "9701bf95e04cf660",
   "outputs": [],
   "execution_count": 286
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:51:53.279163Z",
     "start_time": "2024-12-09T16:51:53.253756Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"Metrics tracking and computation module.\n",
    "\n",
    "This module provides classes and utilities for tracking metrics during training,\n",
    "computing running averages, and managing metric history.\n",
    "\"\"\"\n",
    "\n",
    "from typing import Dict, List, Optional, Union, Any\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from media_bias_detection.utils.logger import general_logger\n",
    "from media_bias_detection.utils.enums import Split\n",
    "\n",
    "class MetricError(Exception):\n",
    "    \"\"\"Custom exception for metric-related errors.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class AverageMeter:\n",
    "    \"\"\"Tracks running average of a metric.\n",
    "\n",
    "    This class maintains a history of values and provides\n",
    "    different methods for computing averages.\n",
    "\n",
    "    Attributes:\n",
    "        name: Name of the metric\n",
    "        values: List of recorded values\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "        self.values: List[float] = []\n",
    "\n",
    "    def update(self, value: float) -> None:\n",
    "        \"\"\"Add a new value to history.\n",
    "\n",
    "        Args:\n",
    "            value: Value to add\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.values.append(float(value))\n",
    "        except (TypeError, ValueError) as e:\n",
    "            raise MetricError(f\"Invalid value for metric {self.name}: {str(e)}\")\n",
    "\n",
    "    def mean_last_k(self, k: int = 10) -> float:\n",
    "        \"\"\"Calculate mean of last k values.\n",
    "\n",
    "        Args:\n",
    "            k: Number of last values to average\n",
    "\n",
    "        Returns:\n",
    "            Mean of last k values\n",
    "\n",
    "        Raises:\n",
    "            MetricError: If not enough values available\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if k < 1:\n",
    "                raise MetricError(\"k must be positive\")\n",
    "            if not self.values:\n",
    "                raise MetricError(\"No values recorded\")\n",
    "            if len(self.values) < k:\n",
    "                return float(\"nan\")\n",
    "            return float(np.mean(self.values[-k:]))\n",
    "        except Exception as e:\n",
    "            raise MetricError(f\"Error computing mean_last_k: {str(e)}\")\n",
    "\n",
    "    def mean_all(self) -> float:\n",
    "        \"\"\"Calculate mean of all values.\n",
    "\n",
    "        Returns:\n",
    "            Mean of all values\n",
    "\n",
    "        Raises:\n",
    "            MetricError: If no values available\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not self.values:\n",
    "                raise MetricError(\"No values recorded\")\n",
    "            return float(np.mean(self.values))\n",
    "        except Exception as e:\n",
    "            raise MetricError(f\"Error computing mean_all: {str(e)}\")\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        \"\"\"Clear all recorded values.\"\"\"\n",
    "        self.values.clear()\n",
    "\n",
    "    def get_history(self) -> List[float]:\n",
    "        \"\"\"Get complete history of values.\n",
    "\n",
    "        Returns:\n",
    "            List of all recorded values\n",
    "        \"\"\"\n",
    "        return self.values.copy()\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        \"\"\"String representation showing latest value.\"\"\"\n",
    "        return f\"{self.mean_last_k(1):.4f}\"\n",
    "\n",
    "\n",
    "class Tracker:\n",
    "    \"\"\"Tracks metrics and losses across training.\n",
    "\n",
    "    This class manages metrics and losses for different splits\n",
    "    and tasks, providing logging and analysis capabilities.\n",
    "\n",
    "    Attributes:\n",
    "        metrics: Nested dictionary of metrics for each split/task\n",
    "        losses: Nested dictionary of losses for each split/task\n",
    "        combined_losses: Dictionary of combined losses per split\n",
    "        logger: Logger instance\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, heads: Dict, logger: Any):\n",
    "        \"\"\"Initialize tracker.\n",
    "\n",
    "        Args:\n",
    "            heads: Dictionary of model heads\n",
    "            logger: Logger instance\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.metrics = self._init_metrics(heads)\n",
    "            self.losses, self.combined_losses = self._init_losses(heads)\n",
    "            self.logger = logger\n",
    "\n",
    "            # Track best metrics\n",
    "            self.best_metrics: Dict[str, float] = {}\n",
    "\n",
    "            general_logger.info(\"Initialized metric tracker\")\n",
    "\n",
    "        except Exception as e:\n",
    "            raise MetricError(f\"Failed to initialize tracker: {str(e)}\")\n",
    "\n",
    "    def _init_metrics(self, heads: Dict) -> Dict:\n",
    "        \"\"\"Initialize metric tracking structures.\n",
    "\n",
    "        Args:\n",
    "            heads: Dictionary of model heads\n",
    "\n",
    "        Returns:\n",
    "            Initialized metrics dictionary\n",
    "        \"\"\"\n",
    "        try:\n",
    "            metrics = {}\n",
    "            for split in Split:\n",
    "                metrics[split] = {\n",
    "                    st_id: {\n",
    "                        m: AverageMeter(name=f\"{st_id}_{split.value}_{m}\")\n",
    "                        for m in head.metrics.keys()\n",
    "                    }\n",
    "                    for st_id, head in heads.items()\n",
    "                }\n",
    "            return metrics\n",
    "\n",
    "        except Exception as e:\n",
    "            raise MetricError(f\"Failed to initialize metrics: {str(e)}\")\n",
    "\n",
    "    def _init_losses(self, heads: Dict) -> tuple:\n",
    "        \"\"\"Initialize loss tracking structures.\n",
    "\n",
    "        Args:\n",
    "            heads: Dictionary of model heads\n",
    "\n",
    "        Returns:\n",
    "            Tuple of (loss_dict, combined_loss_dict)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Task-specific losses\n",
    "            losses = {}\n",
    "            for split in Split:\n",
    "                losses[split] = {\n",
    "                    st_id: AverageMeter(name=f\"{st_id}_{split.value}_loss\")\n",
    "                    for st_id in heads.keys()\n",
    "                }\n",
    "\n",
    "            # Combined losses\n",
    "            combined_losses = {\n",
    "                split: AverageMeter(name=f\"combined_{split.value}_loss\")\n",
    "                for split in Split\n",
    "            }\n",
    "\n",
    "            return losses, combined_losses\n",
    "\n",
    "        except Exception as e:\n",
    "            raise MetricError(f\"Failed to initialize losses: {str(e)}\")\n",
    "\n",
    "    def update_metric(\n",
    "            self,\n",
    "            split: Split,\n",
    "            st_id: str,\n",
    "            metric: str,\n",
    "            value: float\n",
    "    ) -> None:\n",
    "        \"\"\"Update a specific metric value.\n",
    "\n",
    "        Args:\n",
    "            split: Data split\n",
    "            st_id: Subtask ID\n",
    "            metric: Metric name\n",
    "            value: New value\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.metrics[split][st_id][metric].update(value)\n",
    "\n",
    "            # Track best metrics for validation\n",
    "            if split == Split.DEV:\n",
    "                metric_key = f\"{st_id}_{metric}\"\n",
    "                current_value = value\n",
    "                if metric_key not in self.best_metrics or current_value > self.best_metrics[metric_key]:\n",
    "                    self.best_metrics[metric_key] = current_value\n",
    "\n",
    "        except Exception as e:\n",
    "            raise MetricError(f\"Failed to update metric: {str(e)}\")\n",
    "\n",
    "    def update_loss(\n",
    "            self,\n",
    "            split: Split,\n",
    "            st_id: str,\n",
    "            value: float\n",
    "    ) -> None:\n",
    "        \"\"\"Update a specific loss value.\n",
    "\n",
    "        Args:\n",
    "            split: Data split\n",
    "            st_id: Subtask ID\n",
    "            value: New loss value\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.losses[split][st_id].update(value)\n",
    "        except Exception as e:\n",
    "            raise MetricError(f\"Failed to update loss: {str(e)}\")\n",
    "\n",
    "    def update_combined_loss(\n",
    "            self,\n",
    "            split: Split,\n",
    "            value: float\n",
    "    ) -> None:\n",
    "        \"\"\"Update combined loss for a split.\n",
    "\n",
    "        Args:\n",
    "            split: Data split\n",
    "            value: New loss value\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.combined_losses[split].update(value)\n",
    "        except Exception as e:\n",
    "            raise MetricError(f\"Failed to update combined loss: {str(e)}\")\n",
    "\n",
    "    def get_last_st_loss(\n",
    "            self,\n",
    "            split: Split,\n",
    "            st_id: str,\n",
    "            k: int\n",
    "    ) -> float:\n",
    "        \"\"\"Get mean of last k loss values for a subtask.\n",
    "\n",
    "        Args:\n",
    "            split: Data split\n",
    "            st_id: Subtask ID\n",
    "            k: Number of values to average\n",
    "\n",
    "        Returns:\n",
    "            Mean loss value\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self.losses[split][st_id].mean_last_k(k=k)\n",
    "        except Exception as e:\n",
    "            raise MetricError(f\"Failed to get subtask loss: {str(e)}\")\n",
    "\n",
    "    def get_last_st_metric(\n",
    "            self,\n",
    "            split: Split,\n",
    "            st_id: str,\n",
    "            k: int\n",
    "    ) -> float:\n",
    "        \"\"\"Get mean of last k metric values for a subtask.\n",
    "\n",
    "        Args:\n",
    "            split: Data split\n",
    "            st_id: Subtask ID\n",
    "            k: Number of values to average\n",
    "\n",
    "        Returns:\n",
    "            Mean metric value\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Get first metric as representative\n",
    "            first_metric = next(iter(self.metrics[split][st_id]))\n",
    "            return self.metrics[split][st_id][first_metric].mean_last_k(k=k)\n",
    "        except Exception as e:\n",
    "            raise MetricError(f\"Failed to get subtask metric: {str(e)}\")\n",
    "\n",
    "    def log(\n",
    "            self,\n",
    "            splits: List[Split],\n",
    "            additional_payload: Optional[Dict[str, float]] = None\n",
    "    ) -> None:\n",
    "        \"\"\"Log metrics and losses.\n",
    "\n",
    "        Args:\n",
    "            splits: List of splits to log\n",
    "            additional_payload: Optional additional values to log\n",
    "        \"\"\"\n",
    "        try:\n",
    "            out: Dict[str, float] = additional_payload or {}\n",
    "\n",
    "            for split in splits:\n",
    "                # For training and validation, log last values\n",
    "                if split in [Split.DEV, Split.TRAIN]:\n",
    "                    # Log metrics\n",
    "                    metrics = {\n",
    "                        m.name: m.mean_last_k(1)\n",
    "                        for d in self.metrics[split].values()\n",
    "                        for m in d.values()\n",
    "                    }\n",
    "                    # Log losses\n",
    "                    combined_loss = self.combined_losses[split].mean_last_k(1)\n",
    "                    losses = {\n",
    "                        v.name: v.mean_last_k(1)\n",
    "                        for v in self.losses[split].values()\n",
    "                    }\n",
    "                # For test and eval, log means\n",
    "                else:\n",
    "                    # Log metrics\n",
    "                    metrics = {\n",
    "                        m.name: m.mean_all()\n",
    "                        for d in self.metrics[split].values()\n",
    "                        for m in d.values()\n",
    "                    }\n",
    "                    # Log losses\n",
    "                    combined_loss = self.combined_losses[split].mean_all()\n",
    "                    losses = {\n",
    "                        v.name: v.mean_all()\n",
    "                        for v in self.losses[split].values()\n",
    "                    }\n",
    "\n",
    "                out.update(metrics)\n",
    "                out[f\"combined_{split.value}_loss\"] = combined_loss\n",
    "                out.update(losses)\n",
    "\n",
    "            # Log to wandb and local logger\n",
    "            self.logger.log(out)\n",
    "\n",
    "        except Exception as e:\n",
    "            raise MetricError(f\"Failed to log metrics: {str(e)}\")\n",
    "\n",
    "    def save_history(self, path: Union[str, Path]) -> None:\n",
    "        \"\"\"Save complete metric history.\n",
    "\n",
    "        Args:\n",
    "            path: Path to save history\n",
    "        \"\"\"\n",
    "        try:\n",
    "            path = Path(path)\n",
    "            history = {\n",
    "                'metrics': {\n",
    "                    split.value: {\n",
    "                        st_id: {\n",
    "                            metric: meter.get_history()\n",
    "                            for metric, meter in st_metrics.items()\n",
    "                        }\n",
    "                        for st_id, st_metrics in split_metrics.items()\n",
    "                    }\n",
    "                    for split, split_metrics in self.metrics.items()\n",
    "                },\n",
    "                'losses': {\n",
    "                    split.value: {\n",
    "                        st_id: meter.get_history()\n",
    "                        for st_id, meter in split_losses.items()\n",
    "                    }\n",
    "                    for split, split_losses in self.losses.items()\n",
    "                },\n",
    "                'combined_losses': {\n",
    "                    split.value: meter.get_history()\n",
    "                    for split, meter in self.combined_losses.items()\n",
    "                },\n",
    "                'best_metrics': self.best_metrics\n",
    "            }\n",
    "\n",
    "            with open(path, 'w') as f:\n",
    "                json.dump(history, f, indent=2)\n",
    "\n",
    "            general_logger.info(f\"Saved metric history to {path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            raise MetricError(f\"Failed to save history: {str(e)}\")\n",
    "\n",
    "    def load_history(self, path: Union[str, Path]) -> None:\n",
    "        \"\"\"Load metric history.\n",
    "\n",
    "        Args:\n",
    "            path: Path to load history from\n",
    "        \"\"\"\n",
    "        try:\n",
    "            path = Path(path)\n",
    "            with open(path) as f:\n",
    "                history = json.load(f)\n",
    "\n",
    "            # Restore metrics\n",
    "            for split_name, split_metrics in history['metrics'].items():\n",
    "                split = Split(split_name)\n",
    "                for st_id, st_metrics in split_metrics.items():\n",
    "                    for metric, values in st_metrics.items():\n",
    "                        for value in values:\n",
    "                            self.metrics[split][st_id][metric].update(value)\n",
    "\n",
    "            # Restore losses\n",
    "            for split_name, split_losses in history['losses'].items():\n",
    "                split = Split(split_name)\n",
    "                for st_id, values in split_losses.items():\n",
    "                    for value in values:\n",
    "                        self.losses[split][st_id].update(value)\n",
    "\n",
    "            # Restore combined losses\n",
    "            for split_name, values in history['combined_losses'].items():\n",
    "                split = Split(split_name)\n",
    "                for value in values:\n",
    "                    self.combined_losses[split].update(value)\n",
    "\n",
    "            # Restore best metrics\n",
    "            self.best_metrics = history['best_metrics']\n",
    "\n",
    "            general_logger.info(f\"Loaded metric history from {path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            raise MetricError(f\"Failed to load history: {str(e)}\")\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        \"\"\"Reset all metrics and losses.\"\"\"\n",
    "        try:\n",
    "            # Reset metrics\n",
    "            for split_metrics in self.metrics.values():\n",
    "                for st_metrics in split_metrics.values():\n",
    "                    for meter in st_metrics.values():\n",
    "                        meter.reset()\n",
    "\n",
    "            # Reset losses\n",
    "            for split_losses in self.losses.values():\n",
    "                for meter in split_losses.values():\n",
    "                    meter.reset()\n",
    "\n",
    "            # Reset combined losses\n",
    "            for meter in self.combined_losses.values():\n",
    "                meter.reset()\n",
    "\n",
    "            general_logger.info(\"Reset all metrics and losses\")\n",
    "\n",
    "        except Exception as e:\n",
    "            raise MetricError(f\"Failed to reset metrics: {str(e)}\")\n"
   ],
   "id": "69aa4567d124f6cd",
   "outputs": [],
   "execution_count": 287
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:51:53.778124Z",
     "start_time": "2024-12-09T16:51:53.766807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"Checkpoint management module for MTL model.\n",
    "\n",
    "This module handles saving, loading, and managing model checkpoints,\n",
    "including best model tracking and checkpoint rotation.\n",
    "\"\"\"\n",
    "\n",
    "from typing import Dict, Optional, Union, Any\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import json\n",
    "import shutil\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from collections import deque\n",
    "\n",
    "from media_bias_detection.utils.logger import general_logger\n",
    "from media_bias_detection.utils.enums import Split\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CheckpointMetadata:\n",
    "    \"\"\"Container for checkpoint metadata.\n",
    "\n",
    "    Attributes:\n",
    "        epoch: Training epoch number\n",
    "        global_step: Global training step\n",
    "        train_loss: Training loss\n",
    "        val_loss: Validation loss\n",
    "        metrics: Dictionary of metrics\n",
    "        timestamp: When checkpoint was created\n",
    "    \"\"\"\n",
    "    epoch: int\n",
    "    global_step: int\n",
    "    train_loss: float\n",
    "    val_loss: float\n",
    "    metrics: Dict[str, float]\n",
    "    timestamp: float\n",
    "\n",
    "\n",
    "class CheckpointError(Exception):\n",
    "    \"\"\"Custom exception for checkpoint-related errors.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class CheckpointManager:\n",
    "    \"\"\"Manages model checkpoints.\n",
    "\n",
    "    This class handles saving and loading checkpoints, including\n",
    "    maintaining best models and checkpoint rotation.\n",
    "\n",
    "    Attributes:\n",
    "        save_dir: Directory for saving checkpoints\n",
    "        max_checkpoints: Maximum number of checkpoints to keep\n",
    "        checkpoint_name: Base name for checkpoint files\n",
    "        save_best_only: Whether to save only best models\n",
    "        best_metric: Name of metric to track for best model\n",
    "        minimize_metric: Whether metric should be minimized\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            save_dir: Union[str, Path],\n",
    "            max_checkpoints: int = 5,\n",
    "            checkpoint_name: str = \"model\",\n",
    "            save_best_only: bool = False,\n",
    "            best_metric: str = \"val_loss\",\n",
    "            minimize_metric: bool = True\n",
    "    ):\n",
    "        \"\"\"Initialize checkpoint manager.\n",
    "\n",
    "        Args:\n",
    "            save_dir: Directory to save checkpoints in\n",
    "            max_checkpoints: Maximum number of checkpoints to keep\n",
    "            checkpoint_name: Base name for checkpoint files\n",
    "            save_best_only: Whether to save only best models\n",
    "            best_metric: Metric to track for best model\n",
    "            minimize_metric: Whether metric should be minimized\n",
    "        \"\"\"\n",
    "        self.save_dir = Path(save_dir)\n",
    "        self.save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        self.max_checkpoints = max_checkpoints\n",
    "        self.checkpoint_name = checkpoint_name\n",
    "        self.save_best_only = save_best_only\n",
    "        self.best_metric = best_metric\n",
    "        self.minimize_metric = minimize_metric\n",
    "\n",
    "        # Track checkpoints\n",
    "        self.checkpoints = deque(maxlen=max_checkpoints)\n",
    "        self.best_checkpoint: Optional[Path] = None\n",
    "        self.best_metric_value = float('inf') if minimize_metric else float('-inf')\n",
    "\n",
    "        # Load existing checkpoints if any\n",
    "        self._load_existing_checkpoints()\n",
    "\n",
    "        general_logger.info(\n",
    "            f\"Initialized checkpoint manager in {save_dir} \"\n",
    "            f\"(max_checkpoints={max_checkpoints}, save_best_only={save_best_only})\"\n",
    "        )\n",
    "\n",
    "    def _load_existing_checkpoints(self) -> None:\n",
    "        \"\"\"Load information about existing checkpoints.\"\"\"\n",
    "        try:\n",
    "            # Find all checkpoint files\n",
    "            checkpoint_files = sorted(\n",
    "                self.save_dir.glob(f\"{self.checkpoint_name}*.pt\")\n",
    "            )\n",
    "\n",
    "            for checkpoint_file in checkpoint_files:\n",
    "                metadata_file = checkpoint_file.with_suffix('.json')\n",
    "                if metadata_file.exists():\n",
    "                    with open(metadata_file) as f:\n",
    "                        metadata = json.load(f)\n",
    "\n",
    "                    # Update best checkpoint if applicable\n",
    "                    if self.best_metric in metadata['metrics']:\n",
    "                        metric_value = metadata['metrics'][self.best_metric]\n",
    "                        if self._is_better_metric(metric_value):\n",
    "                            self.best_checkpoint = checkpoint_file\n",
    "                            self.best_metric_value = metric_value\n",
    "\n",
    "                    self.checkpoints.append(checkpoint_file)\n",
    "\n",
    "            general_logger.info(\n",
    "                f\"Found {len(self.checkpoints)} existing checkpoints\"\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            raise CheckpointError(f\"Failed to load existing checkpoints: {str(e)}\")\n",
    "\n",
    "    def _is_better_metric(self, new_value: float) -> bool:\n",
    "        \"\"\"Check if new metric value is better than current best.\n",
    "\n",
    "        Args:\n",
    "            new_value: New metric value to compare\n",
    "\n",
    "        Returns:\n",
    "            Whether new value is better\n",
    "        \"\"\"\n",
    "        if self.minimize_metric:\n",
    "            return new_value < self.best_metric_value\n",
    "        return new_value > self.best_metric_value\n",
    "\n",
    "    def _save_metadata(\n",
    "            self,\n",
    "            path: Path,\n",
    "            metadata: CheckpointMetadata\n",
    "    ) -> None:\n",
    "        \"\"\"Save checkpoint metadata to JSON file.\n",
    "\n",
    "        Args:\n",
    "            path: Path to save metadata\n",
    "            metadata: Metadata to save\n",
    "        \"\"\"\n",
    "        try:\n",
    "            metadata_dict = {\n",
    "                'epoch': metadata.epoch,\n",
    "                'global_step': metadata.global_step,\n",
    "                'train_loss': metadata.train_loss,\n",
    "                'val_loss': metadata.val_loss,\n",
    "                'metrics': metadata.metrics,\n",
    "                'timestamp': metadata.timestamp\n",
    "            }\n",
    "\n",
    "            with open(path.with_suffix('.json'), 'w') as f:\n",
    "                json.dump(metadata_dict, f, indent=2)\n",
    "\n",
    "        except Exception as e:\n",
    "            raise CheckpointError(f\"Failed to save metadata: {str(e)}\")\n",
    "\n",
    "    def save(\n",
    "            self,\n",
    "            model: torch.nn.Module,\n",
    "            optimizer: Optional[torch.optim.Optimizer],\n",
    "            scheduler: Optional[torch.optim.lr_scheduler._LRScheduler],\n",
    "            metadata: CheckpointMetadata\n",
    "    ) -> Optional[Path]:\n",
    "        \"\"\"Save model checkpoint.\n",
    "\n",
    "        Args:\n",
    "            model: Model to save\n",
    "            optimizer: Optional optimizer to save\n",
    "            scheduler: Optional scheduler to save\n",
    "            metadata: Checkpoint metadata\n",
    "\n",
    "        Returns:\n",
    "            Path to saved checkpoint if saved, None otherwise\n",
    "\n",
    "        Raises:\n",
    "            CheckpointError: If saving fails\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Check if we should save\n",
    "            metric_value = metadata.metrics.get(self.best_metric)\n",
    "            if self.save_best_only and metric_value is not None:\n",
    "                if not self._is_better_metric(metric_value):\n",
    "                    return None\n",
    "\n",
    "            # Create checkpoint\n",
    "            checkpoint = {\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict() if optimizer else None,\n",
    "                'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
    "                'metadata': {\n",
    "                    'epoch': metadata.epoch,\n",
    "                    'global_step': metadata.global_step,\n",
    "                    'metrics': metadata.metrics\n",
    "                }\n",
    "            }\n",
    "\n",
    "            # Generate checkpoint path\n",
    "            checkpoint_path = self.save_dir / (\n",
    "                f\"{self.checkpoint_name}_epoch{metadata.epoch:03d}.pt\"\n",
    "            )\n",
    "\n",
    "            # Save checkpoint and metadata\n",
    "            torch.save(checkpoint, checkpoint_path)\n",
    "            self._save_metadata(checkpoint_path, metadata)\n",
    "\n",
    "            # Update checkpoint tracking\n",
    "            self.checkpoints.append(checkpoint_path)\n",
    "\n",
    "            # Update best checkpoint if applicable\n",
    "            if metric_value is not None and self._is_better_metric(metric_value):\n",
    "                if self.best_checkpoint is not None:\n",
    "                    old_best = self.best_checkpoint\n",
    "                    if old_best != checkpoint_path:\n",
    "                        shutil.copy(checkpoint_path, self.best_checkpoint.parent / 'best.pt')\n",
    "                else:\n",
    "                    shutil.copy(checkpoint_path, self.save_dir / 'best.pt')\n",
    "                self.best_checkpoint = checkpoint_path\n",
    "                self.best_metric_value = metric_value\n",
    "\n",
    "            # Clean up old checkpoints if necessary\n",
    "            while len(self.checkpoints) > self.max_checkpoints:\n",
    "                old_checkpoint = self.checkpoints.popleft()\n",
    "                if old_checkpoint != self.best_checkpoint:\n",
    "                    old_checkpoint.unlink()\n",
    "                    old_checkpoint.with_suffix('.json').unlink()\n",
    "\n",
    "            general_logger.info(f\"Saved checkpoint to {checkpoint_path}\")\n",
    "            return checkpoint_path\n",
    "\n",
    "        except Exception as e:\n",
    "            raise CheckpointError(f\"Failed to save checkpoint: {str(e)}\")\n",
    "\n",
    "    def load(\n",
    "            self,\n",
    "            path: Optional[Union[str, Path]] = None,\n",
    "            load_best: bool = False,\n",
    "            map_location: Optional[torch.device] = None\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"Load checkpoint.\n",
    "\n",
    "        Args:\n",
    "            path: Path to checkpoint to load, or None for latest\n",
    "            load_best: Whether to load best checkpoint\n",
    "            map_location: Optional device to map tensors to\n",
    "\n",
    "        Returns:\n",
    "            Loaded checkpoint dictionary\n",
    "\n",
    "        Raises:\n",
    "            CheckpointError: If loading fails\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if load_best:\n",
    "                if self.best_checkpoint is None:\n",
    "                    raise CheckpointError(\"No best checkpoint available\")\n",
    "                path = self.best_checkpoint\n",
    "            elif path is None:\n",
    "                if not self.checkpoints:\n",
    "                    raise CheckpointError(\"No checkpoints available\")\n",
    "                path = self.checkpoints[-1]\n",
    "            else:\n",
    "                path = Path(path)\n",
    "\n",
    "            if not path.exists():\n",
    "                raise CheckpointError(f\"Checkpoint not found: {path}\")\n",
    "\n",
    "            checkpoint = torch.load(path, map_location=map_location)\n",
    "            general_logger.info(f\"Loaded checkpoint from {path}\")\n",
    "            return checkpoint\n",
    "\n",
    "        except Exception as e:\n",
    "            raise CheckpointError(f\"Failed to load checkpoint: {str(e)}\")\n",
    "\n",
    "    def get_latest_checkpoint(self) -> Optional[Path]:\n",
    "        \"\"\"Get path to latest checkpoint.\n",
    "\n",
    "        Returns:\n",
    "            Path to latest checkpoint or None if no checkpoints exist\n",
    "        \"\"\"\n",
    "        return self.checkpoints[-1] if self.checkpoints else None\n",
    "\n",
    "    def get_best_checkpoint(self) -> Optional[Path]:\n",
    "        \"\"\"Get path to best checkpoint.\n",
    "\n",
    "        Returns:\n",
    "            Path to best checkpoint or None if no best checkpoint exists\n",
    "        \"\"\"\n",
    "        return self.best_checkpoint\n",
    "\n",
    "    def cleanup(self) -> None:\n",
    "        \"\"\"Remove all checkpoints.\"\"\"\n",
    "        try:\n",
    "            for checkpoint in self.checkpoints:\n",
    "                checkpoint.unlink()\n",
    "                checkpoint.with_suffix('.json').unlink()\n",
    "            self.checkpoints.clear()\n",
    "            self.best_checkpoint = None\n",
    "            self.best_metric_value = float('inf') if self.minimize_metric else float('-inf')\n",
    "            general_logger.info(\"Removed all checkpoints\")\n",
    "\n",
    "        except Exception as e:\n",
    "            raise CheckpointError(f\"Failed to cleanup checkpoints: {str(e)}\")"
   ],
   "id": "aaf673ecdebd12df",
   "outputs": [],
   "execution_count": 288
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:51:54.284394Z",
     "start_time": "2024-12-09T16:51:54.263223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"Training module for MTL model.\n",
    "\n",
    "Provides enhanced training functionality with:\n",
    "- Comprehensive error handling\n",
    "- Memory optimization\n",
    "- Detailed logging\n",
    "- Training efficiency improvements\n",
    "\"\"\"\n",
    "from typing import Dict, List, Optional, Any\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import psutil\n",
    "import torch\n",
    "import statistics as stats\n",
    "from tqdm import tqdm\n",
    "from transformers import get_polynomial_decay_schedule_with_warmup\n",
    "\n",
    "from media_bias_detection.config.config import MAX_NUMBER_OF_STEPS\n",
    "from media_bias_detection.utils.enums import Split, LossScaling\n",
    "from media_bias_detection.utils.logger import general_logger\n",
    "\n",
    "\n",
    "\n",
    "class TrainerError(Exception):\n",
    "    \"\"\"Custom exception for training-related errors.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    \"\"\"Enhanced trainer for MTL model.\n",
    "\n",
    "    Features:\n",
    "    - Automatic mixed precision training\n",
    "    - Memory-optimized batch processing\n",
    "    - Detailed progress tracking\n",
    "    - Comprehensive error handling\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            task_list: List[Task],\n",
    "            initial_lr: float,\n",
    "            model_name: str,\n",
    "            pretrained_path: Optional[str],\n",
    "            sub_batch_size: int,\n",
    "            eval_batch_size: int,\n",
    "            early_stopping_mode,\n",
    "            resurrection: bool,\n",
    "            aggregation_method: AggregationMethod,\n",
    "            loss_scaling: LossScaling,\n",
    "            num_warmup_steps: int,\n",
    "            head_specific_lr_dict: Dict[str, float],\n",
    "            head_specific_patience_dict: Dict[str, int],\n",
    "            head_specific_max_epoch_dict: Dict[str, int],\n",
    "            logger: Logger,\n",
    "            device: Optional[torch.device] = None,\n",
    "            use_amp: bool = True,\n",
    "            *args,\n",
    "            **kwargs,\n",
    "    ):\n",
    "        \"\"\"Initialize trainer with enhanced configuration.\"\"\"\n",
    "        try:\n",
    "            self.logger = logger\n",
    "            general_logger.info(\"Initializing trainer...\")\n",
    "\n",
    "            # Basic setup\n",
    "            self.early_stopping_mode = early_stopping_mode\n",
    "            self.loss_scaling = loss_scaling\n",
    "            self.use_amp = use_amp and torch.cuda.is_available()\n",
    "            self.device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "            self.model, batch_list_train, batch_list_dev, batch_list_eval, batch_list_test = ModelFactory(\n",
    "                task_list=task_list,\n",
    "                sub_batch_size=sub_batch_size,\n",
    "                eval_batch_size=eval_batch_size,\n",
    "                pretrained_path=pretrained_path,\n",
    "                *args,\n",
    "                **kwargs,\n",
    "            )\n",
    "            self.batch_lists = {\n",
    "                Split.TRAIN: batch_list_train,\n",
    "                Split.DEV: batch_list_dev,\n",
    "                Split.EVAL: batch_list_eval,\n",
    "                Split.TEST: batch_list_test,\n",
    "            }\n",
    "\n",
    "            # shared backbone model optimizer\n",
    "            self.lm_optimizer = torch.optim.AdamW(self.model.language_model.backbone.parameters(), lr=initial_lr)\n",
    "            self.lm_lr_scheduler = get_polynomial_decay_schedule_with_warmup(\n",
    "                optimizer=self.lm_optimizer,\n",
    "                num_warmup_steps=num_warmup_steps,\n",
    "                num_training_steps=max([len(dl) for dl in self.batch_lists[Split.TRAIN].dataloaders.values()])\n",
    "                                   * stats.median(head_specific_max_epoch_dict.values()),\n",
    "            )\n",
    "\n",
    "            # task-specifics optimizers\n",
    "            self.head_optimizers = {\n",
    "                str(st_id): torch.optim.AdamW(head.parameters(), lr=head_specific_lr_dict[st_id])\n",
    "                for st_id, head in self.model.heads.items()\n",
    "            }\n",
    "            self.head_lr_schedulers = {\n",
    "                str(st_id): get_polynomial_decay_schedule_with_warmup(\n",
    "                    optimizer=self.head_optimizers[st_id],\n",
    "                    num_warmup_steps=num_warmup_steps,\n",
    "                    num_training_steps=len(self.batch_lists[Split.TRAIN].dataloaders[st_id])\n",
    "                                       * head_specific_max_epoch_dict[st_id],\n",
    "                )\n",
    "                for st_id in self.model.heads.keys()\n",
    "            }\n",
    "\n",
    "            # flags controlling stopping and resurrection\n",
    "            self.task_alive_flags = {str(st_id): True for st_id in self.model.heads.keys()}\n",
    "            self.task_zombie_flags = {str(st_id): False for st_id in self.model.heads.keys()}\n",
    "            self.early_stopper = EarlyStopper(\n",
    "                st_ids=self.model.heads.keys(),\n",
    "                mode=self.early_stopping_mode,\n",
    "                patience=head_specific_patience_dict,\n",
    "                resurrection=resurrection,\n",
    "            )\n",
    "\n",
    "            # Initialize tracking components\n",
    "            self.tracker = Tracker(heads=self.model.heads, logger=logger)\n",
    "            self.GA = GradientAggregator(aggregation_method=aggregation_method)\n",
    "            self.progress_bar = tqdm(range(len(self.model.heads)))\n",
    "            self.model_name = model_name\n",
    "            self.scaling_weights = {str(st.id): st.get_scaling_weight() for t in task_list for st in t.subtasks_list}\n",
    "            self.MAX_NUMBER_OF_STEPS = MAX_NUMBER_OF_STEPS\n",
    "            self.k = 50\n",
    "\n",
    "            # Memory tracking\n",
    "            self._last_memory_check = time.time()\n",
    "            self._memory_check_interval = 60  # seconds\n",
    "\n",
    "            general_logger.info(\n",
    "                f\"Trainer initialized successfully on {self.device}\"\n",
    "                f\"{' with AMP' if self.use_amp else ''}\"\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            general_logger.error(f\"Failed to initialize trainer: {str(e)}\")\n",
    "            raise TrainerError(f\"Failed to initialize trainer: {str(e)}\")\n",
    "\n",
    "    def _optimize_memory(self) -> None:\n",
    "        \"\"\"Perform memory optimization.\"\"\"\n",
    "        try:\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "            process = psutil.Process()\n",
    "            memory_info = process.memory_info().rss / 1024 ** 2  # Convert to MB\n",
    "            general_logger.debug(f\"Current memory usage: {memory_info:.2f} MB\")\n",
    "\n",
    "        except Exception as e:\n",
    "            general_logger.warning(f\"Memory optimization failed: {str(e)}\")\n",
    "\n",
    "    def head_specific_optimization(self, st_id: str, lm_grads, scaling_weight):\n",
    "        \"\"\"\n",
    "        Perform the optimization of a task-specific head.\n",
    "\n",
    "        This method is only called when mode is training.\n",
    "        @param st_id: The subtask id.\n",
    "        @param lm_grads: The LM gradients.\n",
    "        @param scaling_weight: The scaling weight of that subtask.\n",
    "        @return: A dictionary with additional payload containing the conflicting gradients ratio.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            additional_payload = {}\n",
    "            \n",
    "            # Check if we have dev metrics recorded\n",
    "            if self.tracker.losses[Split.DEV][st_id].values:\n",
    "                last_dev_loss = self.tracker.get_last_st_loss(split=Split.DEV, st_id=st_id, k=self.k)\n",
    "                \n",
    "                # Check early stopping conditions only if we have dev metrics\n",
    "                should_stop_now = (\n",
    "                    self.early_stopper.early_stop(st_id=st_id, dev_loss=last_dev_loss)\n",
    "                    if (self.task_alive_flags[st_id] or self.task_zombie_flags[st_id])\n",
    "                    else False\n",
    "                )\n",
    "                \n",
    "                should_resurrect_now = (\n",
    "                    self.early_stopper.resurrect(st_id=st_id, dev_loss=last_dev_loss)\n",
    "                    if (not self.task_zombie_flags[st_id] and not self.task_alive_flags[st_id])\n",
    "                    else False\n",
    "                )\n",
    "                \n",
    "                should_stay_zombie = (\n",
    "                    not self.task_alive_flags[st_id] and \n",
    "                    self.task_zombie_flags[st_id] and \n",
    "                    not should_stop_now\n",
    "                )\n",
    "                \n",
    "                # Update task states based on conditions\n",
    "                if should_stop_now and self.task_alive_flags[st_id]:\n",
    "                    general_logger.info(f\"Subtask {st_id} is now DEAD.\")\n",
    "                    self.eval_st(split=Split.EVAL, st_id=st_id)\n",
    "                    self.tracker.log(splits=[Split.EVAL], additional_payload={st_id + \"_STOPPED\": 0})\n",
    "                    self.progress_bar.update()\n",
    "                \n",
    "                elif should_resurrect_now and not self.task_zombie_flags[st_id]:\n",
    "                    general_logger.info(f\"Subtask {st_id} is now ZOMBIE.\")\n",
    "                    additional_payload[st_id + \"_ZOMBIE\"] = 0\n",
    "                    self.early_stopper.reset_early_stopper(st_id=st_id)\n",
    "                \n",
    "                elif should_stop_now and self.task_zombie_flags[st_id]:\n",
    "                    general_logger.info(f\"Subtask {st_id} is now DEAD AGAIN.\")\n",
    "                    additional_payload[st_id + \"_DEAD_ZOMBIE\"] = 0\n",
    "                    self.early_stopper.reset_early_stopper(st_id=st_id)\n",
    "                \n",
    "                # Update flags\n",
    "                self.task_alive_flags[st_id] = (\n",
    "                    self.task_alive_flags[st_id] and \n",
    "                    not (should_stop_now or self.tracker.get_last_st_metric(split=Split.DEV, st_id=st_id, k=10) == 1)\n",
    "                )\n",
    "                self.task_zombie_flags[st_id] = should_resurrect_now or should_stay_zombie\n",
    "                \n",
    "            else:\n",
    "                # If no dev metrics yet, keep task alive and don't trigger early stopping\n",
    "                should_stop_now = False\n",
    "                self.task_alive_flags[st_id] = True\n",
    "                self.task_zombie_flags[st_id] = False\n",
    "    \n",
    "            # Optimize task if it's alive or zombie\n",
    "            optimize_task = self.task_alive_flags[str(st_id)] or self.task_zombie_flags[str(st_id)]\n",
    "            if optimize_task:\n",
    "                self.head_optimizers[st_id].step()\n",
    "                self.head_lr_schedulers[st_id].step()\n",
    "    \n",
    "            # Update gradients if appropriate\n",
    "            if self.early_stopping_mode != EarlyStoppingMode.BACKBONE or optimize_task:\n",
    "                self.GA.update(lm_grads, scaling_weight=scaling_weight)\n",
    "    \n",
    "            return additional_payload\n",
    "    \n",
    "        except Exception as e:\n",
    "            raise TrainerError(f\"Failed to do head specific optimization: {str(e)}\")\n",
    "\n",
    "\n",
    "    def backbone_optimization(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Perform the optimization of the backbone.\n",
    "\n",
    "        This method is only called when mode is training.\n",
    "        @return: A dictionary with additional payload containing the conflicting gradients ratio.\n",
    "        \"\"\"\n",
    "        # Optimize the LM such that: we aggregate gradients from subtasks and set the final\n",
    "        # gradient to the LM and subsequently optimize (only the LM)\n",
    "        try:\n",
    "            additional_payload = {}\n",
    "            if any(self.task_alive_flags.values()):\n",
    "                aggregated_gradients = self.GA.aggregate_gradients()\n",
    "                self.model.language_model.set_grads(aggregated_gradients)\n",
    "                self.lm_optimizer.step()\n",
    "                self.lm_lr_scheduler.step()\n",
    "            if self.GA.aggregation_method in [AggregationMethod.PCGRAD, AggregationMethod.PCGRAD_ONLINE]:\n",
    "                conflicting_gradients_ratio = self.GA.get_conflicting_gradients_ratio()\n",
    "                additional_payload[\"conflicting_gradients_ratio\"] = conflicting_gradients_ratio\n",
    "        except Exception as e:\n",
    "            raise TrainerError(f\"Failed to do backbone optimization: {str(e)}\")\n",
    "        return additional_payload\n",
    "\n",
    "\n",
    "    def handle_batch(self, batch, split: Split = Split.TRAIN) -> Dict[str, Any]:\n",
    "        \"\"\"Handle a batch.\n",
    "\n",
    "         (always) Pass a batch of sub_batches through the network.\n",
    "         (in train-mode) For each sub_batch, accumulate the gradients of the LM.\n",
    "         For each sub_batch and each st_id,\n",
    "            - (in train-mode) accumulate the gradients of the respective head,\n",
    "            - (always) accumulate the metric of the respective head,\n",
    "            - (always) accumulate the loss of the respective head.\n",
    "        (always) Log all metrics and losses to wandb.\n",
    "         (in train-mode) After all sub_batches are processed, normalize the LM gradients and the head-specific gradients.\n",
    "         (in train-mode) Then, perform the step of the lr_scheduler and the optimizer.\n",
    "\n",
    "        @param batch: The batch containing sub-batches.\n",
    "        @param split: The split (TRAIN, DEV, TEST)\n",
    "        @return: A dictionary containing additional payload that needs to be logged.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            training = split == Split.TRAIN\n",
    "            losses = []\n",
    "            additional_payloads = {}\n",
    "\n",
    "            if training:\n",
    "                self.GA.reset_accumulator()\n",
    "                general_logger.debug(\"Reset gradient accumulator\")\n",
    "\n",
    "            for sub_batch in batch:\n",
    "                if isinstance(sub_batch, BatchData):\n",
    "                    X = sub_batch.input_ids\n",
    "                    attention_masks = sub_batch.attention_mask\n",
    "                    Y = sub_batch.labels\n",
    "                    st_id = sub_batch.subtask_id\n",
    "                else:\n",
    "                    X, attention_masks, Y, st_id = sub_batch\n",
    "                st_id_str = str(st_id.unique().item())\n",
    "\n",
    "                general_logger.debug(f\"Processing sub-batch for task {st_id_str}\")\n",
    "\n",
    "                # Forward pass and compute loss\n",
    "                loss, metric_values, lm_grads = self._step(\n",
    "                    (X, attention_masks, Y, st_id.unique()),\n",
    "                    training=training\n",
    "                )\n",
    "\n",
    "                scaling_weight = (\n",
    "                    self.scaling_weights[st_id_str]\n",
    "                    if self.loss_scaling == LossScaling.STATIC\n",
    "                    else 1.0\n",
    "                )\n",
    "\n",
    "                if training:\n",
    "                    payload = self.head_specific_optimization(\n",
    "                        st_id=st_id_str,\n",
    "                        lm_grads=lm_grads,\n",
    "                        scaling_weight=scaling_weight\n",
    "                    )\n",
    "                    additional_payloads.update(payload)\n",
    "\n",
    "                # Update metrics and losses\n",
    "                for metric, value in metric_values.items():\n",
    "                    self.tracker.update_metric(split=split, st_id=st_id_str, metric=metric, value=value)\n",
    "                self.tracker.update_loss(split=split, st_id=st_id_str, value=loss.item())\n",
    "                losses.append(loss.item())\n",
    "\n",
    "            if training:\n",
    "                payload = self.backbone_optimization()\n",
    "                additional_payloads.update(payload)\n",
    "\n",
    "            mean_loss = np.mean(losses)\n",
    "            self.tracker.update_combined_loss(split=split, value=mean_loss)\n",
    "            general_logger.debug(f\"Batch processed. Mean loss: {mean_loss:.4f}\")\n",
    "\n",
    "            return additional_payloads\n",
    "\n",
    "        except Exception as e:\n",
    "            general_logger.error(f\"Failed to handle batch: {str(e)}\")\n",
    "            raise TrainerError(f\"Batch processing failed: {str(e)}\")\n",
    "\n",
    "    def _step(self, batch, training: bool = True):\n",
    "        \"\"\"Perform a single training/evaluation step.\"\"\"\n",
    "        inputs = {\n",
    "                \"X\": batch[0].to(self.device),\n",
    "                \"attention_masks\": batch[1].to(self.device),\n",
    "                \"Y\": batch[2].to(self.device),\n",
    "                \"st_id\": batch[3]\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            if training:\n",
    "                self.model.train()\n",
    "                self.lm_optimizer.zero_grad()\n",
    "                for optim in self.head_optimizers.values():\n",
    "                    optim.zero_grad()\n",
    "\n",
    "                loss, metric_values = self.model(**inputs)\n",
    "                loss.backward()\n",
    "                lm_gradients = self.model.language_model.get_grads()\n",
    "\n",
    "            else:\n",
    "                self.model.eval()\n",
    "                with torch.no_grad():\n",
    "                    loss, metric_values = self.model(**inputs)\n",
    "                lm_gradients = None\n",
    "\n",
    "            return loss, metric_values, lm_gradients\n",
    "\n",
    "        except Exception as e:\n",
    "            general_logger.error(f\"Step execution failed: {str(e)}\")\n",
    "            raise TrainerError(f\"Step execution failed: {str(e)}\")\n",
    "        \n",
    "        finally:\n",
    "            # Clean up to prevent memory leaks\n",
    "            tensor_keys = [k for k, v in inputs.items() if isinstance(v, torch.Tensor)]\n",
    "            for k in tensor_keys:\n",
    "                del inputs[k]\n",
    "\n",
    "\n",
    "    def fit_debug(self, k: int):\n",
    "        \"\"\"Fit for k iterations only to check if a model can process the data.\"\"\"\n",
    "        try:\n",
    "            general_logger.info(f\"Starting the debug training for {k} iterations\")\n",
    "            step = 0\n",
    "            for _ in range(k):\n",
    "                step += 1\n",
    "                batch = next(self.batch_lists[Split.TRAIN])\n",
    "                self.handle_batch(batch=batch, split=Split.TRAIN)\n",
    "                # Evaluate on dev-batch\n",
    "                batch = next(self.batch_lists[Split.DEV])\n",
    "                self.handle_batch(batch=batch, split=Split.DEV)\n",
    "        except Exception as e:\n",
    "            general_logger.error(f\"Debug training failed: {str(e)}\")\n",
    "            raise TrainerError(f\"Debug training failed: {str(e)}\")\n",
    "\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"Train the model.\"\"\"\n",
    "        try:\n",
    "            general_logger.info(\"Starting training\")\n",
    "            step = 0\n",
    "\n",
    "            while step < self.MAX_NUMBER_OF_STEPS:\n",
    "                if not any(self.task_alive_flags.values()):\n",
    "                    general_logger.info(\"No tasks remaining alive, stopping training\")\n",
    "                    break\n",
    "\n",
    "                step += 1\n",
    "                general_logger.debug(f\"Starting step {step}\")\n",
    "\n",
    "                batch = next(self.batch_lists[Split.TRAIN])\n",
    "                train_payload = self.handle_batch(batch=batch, split=Split.TRAIN)\n",
    "\n",
    "                if step % 3 == 0:\n",
    "                    batch = next(self.batch_lists[Split.DEV])\n",
    "                    dev_payload = self.handle_batch(batch=batch, split=Split.DEV)\n",
    "                    train_payload.update(dev_payload)\n",
    "\n",
    "                self._update_progress()\n",
    "                self.tracker.log(\n",
    "                    splits=[Split.TRAIN, Split.DEV],\n",
    "                    additional_payload=train_payload\n",
    "                )\n",
    "\n",
    "                # Periodic memory optimization\n",
    "                if step % 100 == 0:\n",
    "                    self._optimize_memory()\n",
    "\n",
    "            general_logger.info(\"Training completed\")\n",
    "            self.eval(split=Split.EVAL)\n",
    "\n",
    "        except Exception as e:\n",
    "            general_logger.error(f\"Training failed: {str(e)}\")\n",
    "            raise TrainerError(f\"Training failed: {str(e)}\")\n",
    "\n",
    "\n",
    "    def eval(self, split):\n",
    "        \"\"\"Evaluate the model.\"\"\"\n",
    "        try:\n",
    "            general_logger.info(f\"Starting evaluation on {split}\")\n",
    "            assert split in [Split.EVAL, Split.TEST]\n",
    "\n",
    "            for st_id in self.batch_lists[split].iter_dataloaders.keys():\n",
    "                self.eval_st(split=split, st_id=st_id)\n",
    "\n",
    "            self.tracker.log(splits=[split])\n",
    "            general_logger.info(f\"Evaluation on {split} completed\")\n",
    "\n",
    "        except Exception as e:\n",
    "            general_logger.error(f\"Evaluation failed: {str(e)}\")\n",
    "            raise TrainerError(f\"Evaluation failed: {str(e)}\")\n",
    "\n",
    "\n",
    "    def eval_st(self, split, st_id):\n",
    "        \"\"\"Evaluate on a specific subtask.\"\"\"\n",
    "        try:\n",
    "            general_logger.debug(f\"Evaluating subtask {st_id} on {split}\")\n",
    "            batch_list = self.batch_lists[split]\n",
    "            batch_list._reset()\n",
    "            idl = batch_list.iter_dataloaders[st_id]\n",
    "\n",
    "            for batch in idl:\n",
    "                _ = self.handle_batch(batch=[batch], split=split)\n",
    "\n",
    "        except Exception as e:\n",
    "            general_logger.error(f\"Subtask evaluation failed: {str(e)}\")\n",
    "            raise TrainerError(f\"Subtask evaluation failed: {str(e)}\")\n",
    "\n",
    "\n",
    "    def save_model(self):\n",
    "        \"\"\"Save the trained model.\"\"\"\n",
    "        try:\n",
    "            path = Path(\"model_files\")\n",
    "            path.mkdir(exist_ok=True)\n",
    "            model_path = path / f\"{self.model_name}.pth\"\n",
    "\n",
    "            torch.save(self.model.state_dict(), model_path)\n",
    "            general_logger.info(f\"Model saved to {model_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            general_logger.error(f\"Failed to save model: {str(e)}\")\n",
    "            raise TrainerError(f\"Model saving failed: {str(e)}\")\n",
    "\n",
    "\n",
    "    def _update_progress(self):\n",
    "        \"\"\"Update progress bar.\"\"\"\n",
    "        try:\n",
    "            desc = str(self.tracker)\n",
    "            self.progress_bar.set_description(desc=desc)\n",
    "            self.progress_bar.refresh()\n",
    "\n",
    "        except Exception as e:\n",
    "            general_logger.warning(f\"Failed to update progress bar: {str(e)}\")"
   ],
   "id": "87b131cf65c76f07",
   "outputs": [],
   "execution_count": 289
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Running the experiment\n",
    "For actually running the experiment the configurations from the \"cotrain_random_tasks.py\" were taken and adapted to the changes (MFFLOW logging etc.). \n",
    "Instead of the .fit() method of the trainer class, I use the .fit_debug() method, to check the general ability of the model to process the dta.\n",
    "The experiment was run on the local machine."
   ],
   "id": "5191be2aeb0be3ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:51:56.499757Z",
     "start_time": "2024-12-09T16:51:56.497342Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Current working directory: {os.getcwd()}\")",
   "id": "24be4019d8626b2a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/heddafiedler/Documents/MASTER_DATA_SCIENCE/Semester_3/DL/DL_Project\n"
     ]
    }
   ],
   "execution_count": 290
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:51:57.189580Z",
     "start_time": "2024-12-09T16:51:57.187962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# changing working directory to the root of the project:/Users/heddafiedler/Documents/MASTER_DATA_SCIENCE/Semester_3/DL/DL_Project\n",
    "os.chdir(\"/Users/heddafiedler/Documents/MASTER_DATA_SCIENCE/Semester_3/DL/DL_Project\")"
   ],
   "id": "d7f71cc02cf87461",
   "outputs": [],
   "execution_count": 291
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:51:57.824347Z",
     "start_time": "2024-12-09T16:51:57.820839Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Current working directory: {os.getcwd()}\")",
   "id": "d96efb81f4cdb87e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/heddafiedler/Documents/MASTER_DATA_SCIENCE/Semester_3/DL/DL_Project\n"
     ]
    }
   ],
   "execution_count": 292
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:54:47.256776Z",
     "start_time": "2024-12-09T16:53:16.446862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"Script for executing the experiment 1. Run co-training of all families.\"\"\"\n",
    "import os\n",
    "import wandb\n",
    "from media_bias_detection.utils.enums import Split, AggregationMethod, LossScaling\n",
    "from media_bias_detection.utils.common import set_random_seed\n",
    "from media_bias_detection.config.config import (\n",
    "    head_specific_lr,\n",
    "    head_specific_max_epoch,\n",
    "    head_specific_patience)\n",
    "\n",
    "EXPERIMENT_NAME = \"experiment_baseline_check\"\n",
    "MODEL_NAME = \"baseline_check\"\n",
    "selected_tasks = [cw_hard_03,\n",
    "me_too_ma_108,\n",
    "good_news_everyone_42]\n",
    "\n",
    "tasks = selected_tasks\n",
    "\n",
    "for t in tasks:\n",
    "    for st in t.subtasks_list:\n",
    "        st.process()\n",
    "\n",
    "\n",
    "# training config\n",
    "config = {\n",
    "   \"sub_batch_size\": 32,\n",
    "   \"eval_batch_size\": 128,\n",
    "   \"initial_lr\": 4e-5,\n",
    "   \"dropout_prob\": 0.1,\n",
    "   \"hidden_dimension\": 768,\n",
    "   \"input_dimension\": 768,\n",
    "   \"aggregation_method\": AggregationMethod.MEAN,\n",
    "   \"early_stopping_mode\": EarlyStoppingMode.HEADS,\n",
    "   \"loss_scaling\": LossScaling.STATIC,\n",
    "   \"num_warmup_steps\": 10,\n",
    "   \"pretrained_path\": None,\n",
    "   \"resurrection\": True,\n",
    "   \"model_name\": \"YOUR_MODEL_NAME\",\n",
    "   \"head_specific_lr_dict\": head_specific_lr,\n",
    "   \"head_specific_patience_dict\": head_specific_patience,\n",
    "   \"head_specific_max_epoch_dict\": head_specific_max_epoch,\n",
    "   \"logger\": Logger(EXPERIMENT_NAME),\n",
    " }\n",
    "\n",
    "set_random_seed() # default is 321\n",
    "#wandb.init(project=EXPERIMENT_NAME,name=MODEL_NAME)\n",
    "trainer = Trainer(task_list=tasks, **config)\n",
    "trainer.fit_debug(k=1)\n",
    "trainer.eval(split=Split.TEST)\n",
    "trainer.save_model()\n",
    "#wandb.finish()"
   ],
   "id": "6779ca63c6f7366d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-12-09 17:53:16,451: INFO: 1312152763: Processing SubTask 300001]\n",
      "[2024-12-09 17:53:16,982: INFO: 1312152763: SubTask 300001 processed successfully. Splits: Train=5474, Dev=684, Test=685]\n",
      "[2024-12-09 17:53:16,983: INFO: 1312152763: Processing SubTask 10801]\n",
      "Loading data for MultiLabelClassificationSubTask 10801\n",
      "X type: <class 'pandas.core.series.Series'>\n",
      "Y type: <class 'pandas.core.frame.DataFrame'>\n",
      "X shape: 7388\n",
      "Y shape: (7388, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [25:17<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: torch.Size([7388, 128])\n",
      "Y shape: torch.Size([7388, 2])\n",
      "Attention masks shape: torch.Size([7388, 128])\n",
      "[2024-12-09 17:53:18,060: INFO: 1312152763: SubTask 10801 processed successfully. Splits: Train=5910, Dev=738, Test=740]\n",
      "[2024-12-09 17:53:18,061: INFO: 1312152763: Processing SubTask 42001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-12-09 17:53:18,446: INFO: 1312152763: SubTask 42001 processed successfully. Splits: Train=3542, Dev=442, Test=444]\n",
      "[2024-12-09 17:53:18,447: INFO: 1312152763: Processing SubTask 42002]\n",
      "[2024-12-09 17:53:18,812: INFO: 1312152763: SubTask 42002 processed successfully. Splits: Train=3542, Dev=442, Test=444]\n",
      "[2024-12-09 17:53:18,817: INFO: 2527385809: Initializing trainer...]\n",
      "[2024-12-09 17:53:18,817: INFO: 4203745325: Initializing backbone language model]\n",
      "Creating ClassificationHead for subtask 300001\n",
      "num_classes: 2\n",
      "Initializing ClassificationHead\n",
      "num_classes: 2\n",
      "num_labels: 1\n",
      "Initializing ClassificationHead with 1 labels\n",
      "Creating MultiLabelClassificationHead for subtask 10801\n",
      "num_classes: 2, num_labels: 2\n",
      "Initializing ClassificationHead\n",
      "num_classes: 2\n",
      "num_labels: 2\n",
      "Initializing ClassificationHead with 2 labels\n",
      "[2024-12-09 17:53:19,144: INFO: 2558031327: Initialized TokenClassificationHead with 3 classes]\n",
      "[2024-12-09 17:53:19,146: INFO: 2558031327: Initialized TokenClassificationHead with 3 classes]\n",
      "[2024-12-09 17:53:19,148: INFO: 3023969827: Initialized model with 4 heads on cpu]\n",
      "[2024-12-09 17:53:19,149: INFO: 2808285950: Creating BatchList with 4 subtasks, batch size 32]\n",
      "[2024-12-09 17:53:19,149: INFO: 2808285950: Initializing dataset for subtask 300001 with split Split.TRAIN]\n",
      "[2024-12-09 17:53:19,151: INFO: 2808285950: Resetting dataset for subtask 300001]\n",
      "[2024-12-09 17:53:19,154: INFO: 2808285950: Initializing dataset for subtask 10801 with split Split.TRAIN]\n",
      "[2024-12-09 17:53:19,154: INFO: 2808285950: Resetting dataset for subtask 10801]\n",
      "[2024-12-09 17:53:19,155: INFO: 2808285950: Initializing dataset for subtask 42001 with split Split.TRAIN]\n",
      "[2024-12-09 17:53:19,156: INFO: 2808285950: Resetting dataset for subtask 42001]\n",
      "[2024-12-09 17:53:19,157: INFO: 2808285950: Initializing dataset for subtask 42002 with split Split.TRAIN]\n",
      "[2024-12-09 17:53:19,157: INFO: 2808285950: Resetting dataset for subtask 42002]\n",
      "[2024-12-09 17:53:19,159: INFO: 2808285950: Creating BatchList with 4 subtasks, batch size 128]\n",
      "[2024-12-09 17:53:19,159: INFO: 2808285950: Initializing dataset for subtask 300001 with split Split.DEV]\n",
      "[2024-12-09 17:53:19,159: INFO: 2808285950: Resetting dataset for subtask 300001]\n",
      "[2024-12-09 17:53:19,161: INFO: 2808285950: Initializing dataset for subtask 10801 with split Split.DEV]\n",
      "[2024-12-09 17:53:19,161: INFO: 2808285950: Resetting dataset for subtask 10801]\n",
      "[2024-12-09 17:53:19,162: INFO: 2808285950: Initializing dataset for subtask 42001 with split Split.DEV]\n",
      "[2024-12-09 17:53:19,162: INFO: 2808285950: Resetting dataset for subtask 42001]\n",
      "[2024-12-09 17:53:19,163: INFO: 2808285950: Initializing dataset for subtask 42002 with split Split.DEV]\n",
      "[2024-12-09 17:53:19,163: INFO: 2808285950: Resetting dataset for subtask 42002]\n",
      "[2024-12-09 17:53:19,164: INFO: 2808285950: Initializing dataset for subtask 300001 with split Split.DEV]\n",
      "[2024-12-09 17:53:19,165: INFO: 2808285950: Resetting dataset for subtask 300001]\n",
      "[2024-12-09 17:53:19,166: INFO: 2808285950: Initializing dataset for subtask 10801 with split Split.DEV]\n",
      "[2024-12-09 17:53:19,166: INFO: 2808285950: Resetting dataset for subtask 10801]\n",
      "[2024-12-09 17:53:19,167: INFO: 2808285950: Initializing dataset for subtask 42001 with split Split.DEV]\n",
      "[2024-12-09 17:53:19,167: INFO: 2808285950: Resetting dataset for subtask 42001]\n",
      "[2024-12-09 17:53:19,168: INFO: 2808285950: Initializing dataset for subtask 42002 with split Split.DEV]\n",
      "[2024-12-09 17:53:19,169: INFO: 2808285950: Resetting dataset for subtask 42002]\n",
      "[2024-12-09 17:53:19,170: INFO: 2808285950: Initializing dataset for subtask 300001 with split Split.TEST]\n",
      "[2024-12-09 17:53:19,170: INFO: 2808285950: Resetting dataset for subtask 300001]\n",
      "[2024-12-09 17:53:19,171: INFO: 2808285950: Initializing dataset for subtask 10801 with split Split.TEST]\n",
      "[2024-12-09 17:53:19,171: INFO: 2808285950: Resetting dataset for subtask 10801]\n",
      "[2024-12-09 17:53:19,172: INFO: 2808285950: Initializing dataset for subtask 42001 with split Split.TEST]\n",
      "[2024-12-09 17:53:19,173: INFO: 2808285950: Resetting dataset for subtask 42001]\n",
      "[2024-12-09 17:53:19,173: INFO: 2808285950: Initializing dataset for subtask 42002 with split Split.TEST]\n",
      "[2024-12-09 17:53:19,174: INFO: 2808285950: Resetting dataset for subtask 42002]\n",
      "[2024-12-09 17:53:19,176: INFO: 4006134754: Initialized early stopping manager with mode EarlyStoppingMode.HEADS]\n",
      "[2024-12-09 17:53:19,176: INFO: 382814918: Initialized metric tracker]\n",
      "[2024-12-09 17:53:19,177: INFO: 167095286: Initialized GradientAggregator with AggregationMethod.MEAN]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-12-09 17:53:19,178: INFO: 2527385809: Trainer initialized successfully on cpu]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [18:43<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-12-09 17:53:19,282: INFO: 2527385809: Starting the debug training for 1 iterations]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 2])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 2])\n",
      "Logits shape: torch.Size([32, 4])\n",
      "Batch size: 128\n",
      "X shape: torch.Size([128, 128, 768])\n",
      "y shape: torch.Size([128, 1])\n",
      "Logits shape: torch.Size([128, 2])\n",
      "Batch size: 128\n",
      "X shape: torch.Size([128, 128, 768])\n",
      "y shape: torch.Size([128, 2])\n",
      "Logits shape: torch.Size([128, 4])\n",
      "[2024-12-09 17:53:42,483: INFO: 2527385809: Starting evaluation on Split.TEST]\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 2])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 2])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 2])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 2])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 2])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 2])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 2])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 2])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 2])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 2])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 2])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 2])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 2])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 2])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 2])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 2])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 2])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 2])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 2])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 2])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 2])\n",
      "Batch size: 13\n",
      "X shape: torch.Size([13, 128, 768])\n",
      "y shape: torch.Size([13, 1])\n",
      "Logits shape: torch.Size([13, 2])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 2])\n",
      "Logits shape: torch.Size([32, 4])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 2])\n",
      "Logits shape: torch.Size([32, 4])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 2])\n",
      "Logits shape: torch.Size([32, 4])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 2])\n",
      "Logits shape: torch.Size([32, 4])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 2])\n",
      "Logits shape: torch.Size([32, 4])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 2])\n",
      "Logits shape: torch.Size([32, 4])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 2])\n",
      "Logits shape: torch.Size([32, 4])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 2])\n",
      "Logits shape: torch.Size([32, 4])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 2])\n",
      "Logits shape: torch.Size([32, 4])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 2])\n",
      "Logits shape: torch.Size([32, 4])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 2])\n",
      "Logits shape: torch.Size([32, 4])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 2])\n",
      "Logits shape: torch.Size([32, 4])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 2])\n",
      "Logits shape: torch.Size([32, 4])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 2])\n",
      "Logits shape: torch.Size([32, 4])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 2])\n",
      "Logits shape: torch.Size([32, 4])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 2])\n",
      "Logits shape: torch.Size([32, 4])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 2])\n",
      "Logits shape: torch.Size([32, 4])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 2])\n",
      "Logits shape: torch.Size([32, 4])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 2])\n",
      "Logits shape: torch.Size([32, 4])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 2])\n",
      "Logits shape: torch.Size([32, 4])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 2])\n",
      "Logits shape: torch.Size([32, 4])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 2])\n",
      "Logits shape: torch.Size([32, 4])\n",
      "Batch size: 32\n",
      "X shape: torch.Size([32, 128, 768])\n",
      "y shape: torch.Size([32, 2])\n",
      "Logits shape: torch.Size([32, 4])\n",
      "Batch size: 4\n",
      "X shape: torch.Size([4, 128, 768])\n",
      "y shape: torch.Size([4, 2])\n",
      "Logits shape: torch.Size([4, 4])\n",
      "[2024-12-09 17:54:46,879: INFO: 4006134754: {'300001_test_f1': 0.0, '300001_test_acc': 0.7411494756286795, '10801_test_f1': 0.06904325370366375, '10801_test_acc': 0.5188802083333334, '42001_test_f1': 0.2746167576738766, '42001_test_acc': 0.5072752003158841, '42002_test_f1': 0.2501947901078633, '42002_test_acc': 0.3710079405988966, 'combined_test_loss': 0.8154458484134158, '300001_test_loss': 0.645875871181488, '10801_test_loss': 0.6607970048983892, '42001_test_loss': 1.0691016742161341, '42002_test_loss': 1.0933694328580583}]\n",
      "[2024-12-09 17:54:46,885: INFO: 2527385809: Evaluation on Split.TEST completed]\n",
      "[2024-12-09 17:54:47,253: INFO: 2527385809: Model saved to model_files/YOUR_MODEL_NAME.pth]\n"
     ]
    }
   ],
   "execution_count": 294
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:55:24.922159Z",
     "start_time": "2024-12-09T16:55:24.911859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#model architecture check\n",
    "def print_model_summary(model):\n",
    "    \"\"\"Create a detailed custom model summary.\"\"\"\n",
    "    backbone_params = sum(p.numel() for p in model.language_model.backbone.parameters())\n",
    "    \n",
    "    print(\"=== MTL Model Summary ===\")\n",
    "    print(f\"\\nBackbone: DistilBERT\")\n",
    "    print(f\"Backbone Parameters: {backbone_params:,}\")\n",
    "    \n",
    "    print(\"\\nTask Heads:\")\n",
    "    for task_id, head in model.heads.items():\n",
    "        head_params = sum(p.numel() for p in head.parameters())\n",
    "        print(f\"\\nTask {task_id}:\")\n",
    "        print(f\"  Type: {head.__class__.__name__}\")\n",
    "        print(f\"  Parameters: {head_params:,}\")\n",
    "        \n",
    "        # Head-specific details\n",
    "        if isinstance(head, ClassificationHead):\n",
    "            print(f\"  Classes: {head.num_classes}\")\n",
    "            print(f\"  Labels: {head.num_labels}\")\n",
    "            print(f\"  Metrics: {list(head.metrics.keys())}\")\n",
    "            \n",
    "        elif isinstance(head, TokenClassificationHead):\n",
    "            print(f\"  Classes: {head.num_classes}\")\n",
    "            print(f\"  Metrics: {list(head.metrics.keys())}\")\n",
    "            \n",
    "        elif isinstance(head, RegressionHead):\n",
    "            print(f\"  Output Dimension: 1\")\n",
    "            print(f\"  Metrics: {list(head.metrics.keys())}\")\n",
    "    \n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"\\nTotal Parameters: {total_params:,}\")\n",
    "    \n",
    "    # Task distribution summary\n",
    "    head_types = {}\n",
    "    for head in model.heads.values():\n",
    "        head_type = head.__class__.__name__\n",
    "        head_types[head_type] = head_types.get(head_type, 0) + 1\n",
    "    \n",
    "    print(\"\\nTask Distribution:\")\n",
    "    for head_type, count in head_types.items():\n",
    "        print(f\"  {head_type}: {count}\")\n",
    "\n",
    "# Use it\n",
    "print_model_summary(trainer.model)"
   ],
   "id": "48e77f1982b0bf1e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MTL Model Summary ===\n",
      "\n",
      "Backbone: DistilBERT\n",
      "Backbone Parameters: 66,362,880\n",
      "\n",
      "Task Heads:\n",
      "\n",
      "Task 300001:\n",
      "  Type: ClassificationHead\n",
      "  Parameters: 592,130\n",
      "  Classes: 2\n",
      "  Labels: 1\n",
      "  Metrics: ['f1', 'acc']\n",
      "\n",
      "Task 10801:\n",
      "  Type: ClassificationHead\n",
      "  Parameters: 593,668\n",
      "  Classes: 2\n",
      "  Labels: 2\n",
      "  Metrics: ['f1', 'acc']\n",
      "\n",
      "Task 42001:\n",
      "  Type: TokenClassificationHead\n",
      "  Parameters: 2,307\n",
      "  Classes: 3\n",
      "  Metrics: ['f1', 'acc']\n",
      "\n",
      "Task 42002:\n",
      "  Type: TokenClassificationHead\n",
      "  Parameters: 2,307\n",
      "  Classes: 3\n",
      "  Metrics: ['f1', 'acc']\n",
      "\n",
      "Total Parameters: 67,553,292\n",
      "\n",
      "Task Distribution:\n",
      "  ClassificationHead: 2\n",
      "  TokenClassificationHead: 2\n"
     ]
    }
   ],
   "execution_count": 295
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8b01c3336c8986a4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
